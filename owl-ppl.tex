\documentclass[sigconf]{acmart}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
% \setcopyright{acmcopyright}
% \copyrightyear{2018}
% \acmYear{2018}
% \acmDOI{10.1145/1122445.1122456}

%% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[Woodstock '18]{Woodstock '18: ACM Symposium on Neural
%   Gaze Detection}{June 03--05, 2018}{Woodstock, NY}
% \acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%   June 03--05, 2018, Woodstock, NY}
% \acmPrice{15.00}
% \acmISBN{978-1-4503-XXXX-X/18/06}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
\acmSubmissionID{74}

\usepackage{subcaption}

\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepgfplotslibrary{groupplots}
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.13}

\usepackage{placeins}

\usepackage{pifont}
\definecolor{green1}{rgb}{0.0, 0.5, 0.0}
\definecolor{red1}{rgb}{1.0, 0.01, 0.24}
\newcommand{\cmark}{\textcolor{green1}{\checkmark}}%
\newcommand{\xmark}{\textcolor{red1}{\ding{55}}}%

\usepackage[outputdir=out, cache=false]{minted}
\setminted{fontsize=\footnotesize}
\newmintedfile[ocamlcode]{ocaml}{frame=single,framesep=7pt}
\newmintedfile[jscode]{js}{frame=single,framesep=7pt}
\newmintedfile[clojurecode]{clj}{frame=single,framesep=7pt}
\newminted[ocamlcode-in]{ocaml}{frame=single,framesep=7pt,autogobble}

\usepackage{xpatch,letltxmacro}
\LetLtxMacro{\cminted}{\minted}
\let\endcminted\endminted
\xpretocmd{\cminted}{\RecustomVerbatimEnvironment{Verbatim}{BVerbatim}{}}{}{}

\usepackage{xspace}

\newcommand\note[2]{\color{#1}\bf #2}
\newcommand\mort[1]{{\note{red}{mort: #1}}}
% \newcommand\mortl[1]{{\color{red} mort: \begin{itemize}#1\end{itemize}}}

\newcommand{\one}{({\em i})\/}
\newcommand{\two}{({\em ii})\/}
\newcommand{\three}{({\em iii})\/}
\newcommand{\four}{({\em iv})\/}
\newcommand{\five}{({\em v})\/}

\newcommand{\sampling}{\emph{sampling}\xspace}
\newcommand{\s}[1]{(\S\ref{#1})}

\newcommand{\pupil}{Pupil\xspace}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{
  \pupil, an Efficient Trace-Based, Type-Safe \\
  Probabilistic Programming Language
}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Anik Roy}
\authornote{Work carried out for final year undergraduate project.}
\affiliation{%
  \institution{Christ's College}
  \city{Cambridge University}
  \country{UK}
}
\email{anik545@gmail.com}

\author{Richard Mortier}
\affiliation{%
  \institution{Department of Computer Science \& Technology}
  \city{Cambridge University}
  \country{UK}
}
\email{richard.mortier@cl.cam.ac.uk}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Creating statistical models and performing inference on these models is key to data science. A probabilistic programming language (PPL) is a language for creating complex models by composing simpler models and probability distributions, separating inference from model specification, allowing inference to be performed automatically~\cite{gordon2014probabilistic}. We present \emph{\pupil}, a shallow embedded PPL in the OCaml language that leverages OCaml's expressive type system and efficient native code generation. We compare \pupil's performance to that of two well-known alternative PPLs, Anglican and WebPPL, We find that \pupil outperforms WebPPL in inference speed and is commensurate with Anglican, and in both cases uses substantially less memory, making it particularly appropriate for use in edge computing applications.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
% \begin{CCSXML}
%   <ccs2012>
%   <concept>
%   <concept_id>10010520.10010553.10010562</concept_id>
%   <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%   <concept_significance>500</concept_significance>
%   </concept>
%   <concept>
%   <concept_id>10010520.10010575.10010755</concept_id>
%   <concept_desc>Computer systems organization~Redundancy</concept_desc>
%   <concept_significance>300</concept_significance>
%   </concept>
%   <concept>
%   <concept_id>10010520.10010553.10010554</concept_id>
%   <concept_desc>Computer systems organization~Robotics</concept_desc>
%   <concept_significance>100</concept_significance>
%   </concept>
%   <concept>
%   <concept_id>10003033.10003083.10003095</concept_id>
%   <concept_desc>Networks~Network reliability</concept_desc>
%   <concept_significance>100</concept_significance>
%   </concept>
%   </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Computer systems organization~Embedded systems}
% \ccsdesc[300]{Computer systems organization~Redundancy}
% \ccsdesc{Computer systems organization~Robotics}
% \ccsdesc[100]{Networks~Network reliability}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
% \keywords{datasets, neural networks, gaze detection, text tagging}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
\label{s:introduction}

Creating statistical models and performing inference on these models is key to data science. Such modelling involves formulating a prior belief over some parameters ($x$), the generative model ($p(x)$), and a set of conditions ($p(y|x)$) which specify the likelihood of observed data given the parameters. The goal is then to find the posterior, the (inferred) distribution over the parameters given the data we observe ($p(x|y)$). As this is generally intractable, approximate methods are used -- but it can be difficult to disentangle the approximation method from the model, reducing re-usability of methods and robustness of implementation.

A probabilistic programming language (PPL) is a language for creating complex models by composing simpler models and probability distributions, separating inference from model specification, allowing inference to be performed automatically~\cite{gordon2014probabilistic}. This has numerous advantages: inference code is written and optimised once, independent of model; many different inference algorithms can be provided, suitable for different problems; and models can be written by domain experts, without concern for inference.~\s{s:related}

PPLs can be standalone languages or embedded into another language, giving access to the full power of the host language, making it easier to combine models. We present \emph{\pupil}, a shallow embedded PPL in the OCaml language that leverages OCaml's expressive type system and efficient native code generation. \pupil can represent a wide variety of models, not limited to finite graphical models or discrete distributions, and provides several inference procedures. Distributions are represented using a Generalised Algebraic Data Type (GADT) as a monad, allowing distributions to be combined type-safely to build models.~\s{s:pupil}

We show that \pupil's inference algorithms are correct using statistical tests on simple programs that can be solved analytically. We compare \pupil's performance to that of two well-known alternative PPLs, Anglican and WebPPL, We find that \pupil outperforms WebPPL in inference speed, and is commensurate with Anglican. In both cases, \pupil exhibits significantly lower memory usage making it particularly suitable for low-resource availability environments such as edge computing.~\s{s:evaluation}

\section{Related Work}
\label{s:related}

\begin{table}
  \centering
  \begin{tabular}{ l l c c l }
    \toprule
    \textbf{PPL}
    & \textbf{Host}
    & \textbf{Universal?}
    & \textbf{Continuous?}
    & \textbf{Year} \\
    \midrule

    BUGS~\cite{gilks1994bugs}
    & --- & \xmark & \cmark & 1994 \\

    IBAL~\cite{ibal}
    & OCaml & \xmark & \xmark & 2000 \\

    JAGS~\cite{plummer2004jags}
    & --- & \xmark & \cmark & 2004 \\

    Erwig~\cite{erwig}
    & Haskell & \cmark & \cmark & 2006\\

    Church~\cite{goodman2012church}
    & LISP & \cmark & \cmark & 2008 \\

    HANSEI~\cite{kiselyov2009embedded}
    & OCaml & \xmark & \xmark & 2009 \\

    Infer.NET~\cite{wang2011using}
    & F\# & \xmark & \cmark & 2011 \\

    STAN~\cite{carpenter2017stan}
    & --- & \xmark & \cmark & 2012 \\

    Anglican~\cite{anglican-smc}
    & Clojure & \cmark & \cmark & 2014 \\

    Edward~\cite{edward}
    & --- & \xmark & \cmark & 2017\\

    WebPPL~\cite{mobus2018structure}
    & JavaScript & \cmark & \cmark & 2018 \\

    Pyro~\cite{bingham2019pyro}
    & Python & \cmark & \cmark & 2019 \\

    \pupil
    & OCaml & \cmark & \cmark & 2020 \\
    \bottomrule
  \end{tabular}
  \caption{A selection of current PPLs, their host languages, and whether they are universal and support continuous distributions.}
  \label{tab:ppl-summ}
\end{table}

There are many examples of PPLs, both as DSLs embedded into other languages (including OCaml) and as standalone compilers. Standalone languages have their own syntax and compiler, so can be fine tuned to the task of inference, but often lack features since they have to be built from scratch. Embedded languages can utilise facilities in their host language, such as type checking, compilers or libraries, as well as allowing programs to be integrated into existing systems easily, but they must work around the syntax and semantics of the host language. Some early PPLs, such as BUGS~\cite{gilks1994bugs} or JAGS~\cite{plummer2004jags}, limited the types of models representable in the language to finite graphical models, where the model could be expressed as a static graph of random variables and their relationships.

Many languages restrict the set of allowed models in order to use more efficient inference algorithms which can take advantage of the restricted structure of models. Universal languages can represent any model, but suffer from less predictable inference procedures since many properties of the model (such as the number of random variables) are not available at compile-time. Restricting the types of possible models can lead to efficient implementations of inference algorithms. Languages such as STAN~\cite{carpenter2017stan} or Infer.NET~\cite{wang2011using} exploit this, and do not allow, for example, unbounded recursion when defining models.

PPLs which can express models that have an unlimited number of random variables (and so do not compile to a static graph) are known as `universal'~\cite{borgstrom2016lambda}, and include Church~\cite{goodman2012church}, WebPPL~\cite{mobus2018structure} and Anglican~\cite{anglican-smc}. These tend to be slower at inference due to the need to support a greater range of models. Some PPLs restrict the types of distribution allowed, for example HANSEI~\cite{kiselyov2009embedded} and IBAL~\cite{ibal} only allow discrete distributions.

There are two principle approaches to the implementation of PPLs. \one~Graph-based, where a finite graph representing the variables and their relationships, over which efficient inference can take place, is generated from a program, e.g,~Infer.NET~\cite{wang2011using} or JAGS~\cite{plummer2004jags}. It has the benefit of being able to process high-dimensional data well as efficient computation graph frameworks can be leveraged, e.g.,~Edward~\cite{edward}, which uses TensorFlow~\cite{tensorflow} as a backend. However, it does restrict the types of models to those that can be represented by the underlying graph. \two~Trace-based, where execution traces corresponding to each run of a program with intermediate random variables taki a particular value, are reasoned over by inference algorithms to produce a posterior distribution~\cite{anglican-smc,mobus2018structure}. This can lead to greater expressiveness as we are not limited by the constraints of a graph, but inference is often slower as more general purpose algorithms must be used.

Prior PPLs embedded in OCaml include IBAL~\cite{ibal} and HANSEI~\cite{kiselyov2009embedded}, and \pupil takes some inspiration from these particularly in implementation of efficient inference engines. A summary of several PPLs is given in Table \ref{tab:ppl-summ}.

\section{\pupil, an OCaml PPL}
\label{s:pupil}

\pupil is shallowly embedded in the OCaml language, and makes use of features such as its strong type-system to ensure programs that compile will run, algebraic datatypes to represent probabilistic programs as trees, and pattern matching to simplify interpretation and transformation of these trees. \pupil builds on Owl, a scientific computing library written for OCaml~\cite{owl} containing functions for working with a wide variety of probability distributions, as well as to find their probability density function (pdf) and to sample efficiently from them, the functions required to perform inference.

Using a shallow embedding means we can use all of the features of OCaml as normal, including branching (if/then/else), loops, references, let bindings, (higher-order) functions, and recursion. This has the benefit of leveraging OCaml features such as type checking, as well as permitting library code to be included directly within models. It also allows for recursively defined models, which can be non-terminating (and therefore invalid) models. However, we can write functions which are \textit{stochastic recursive}~\cite{siegmund}, that is, functions which have a probability of termination that tends to 1 as the number of successive calls tends to infinity. This leads to functions which terminate their recursion non-deterministically. Any model which does not satisfy this will be considered an invalid model, though the halting problem unfortunately means this property cannot be enforced.

The shallow embedding results in the provision of two operations to OCaml: \emph{sample}, for taking a sample from a distribution whether primitive or another (sub-)model; and \emph{condition}, for conditioning on observations, defining how likely is observed data (called \emph{observe} or \emph{score} in other PPLs).

The problem of designing a PPL is then finding a way to model the nondeterminism in the sample operator and integrate the information from the condition operator to guide inference and the execution traces explored. Most universal PPLs use a feature that enables exploring subcomputations - the different execution traces. This can be done using continuation passing style (CPS) transformations, as in WebPPL and Church~\cite{mobus2018structure,goodman2012church}, or algebraic effects as in Pyro~\cite{bingham2019pyro}. In \pupil we model conditional distributions as monads~\cite{scibior2015practical}, and realise probabilistic programs as a GADT.

\subsection{Monads}
Monads are a design pattern commonly used in functional programming languages.

The key data structure I use to model probability distributions is a monad. A data type is a monad if it defines two operations, \texttt{return} and \texttt{bind}, and can be thought of as a type which `wrap' values. The return function takes a value and returns a monad wrapping that value. The bind function takes a monad and a function, and applies the function to the value wrapped inside the monad, and then re-wraps this value. The type must also satisfy a set of laws, which I omit here~\cite{wadler1990comprehending}. Monads can be used to structure programs in a general way, and allow side effects to be described in types.

\paragraph{Probability Monad} \label{sec:prep-monad}
It has been shown that probability distributions form a monad,~\cite{giry1982categorical, jones1989probabilistic}, and that they can be used to create distributions composed from other distributions~\cite{ramsey2002stochastic}. In this case, \texttt{return x} represents a distribution with only one value (x) - known as a Dirac distribution. So \texttt{bind d f} is the main operator for composing distributions. Binding distributions together represents taking the output of one distribution (d) and using it in the body of the function (f). This can be thought of as taking a sample from d. However, it is important to note that calling bind will not directly produce a sample, but expose that structure to an interpreter (the inference engine) which can then decide what to do at that point.

\paragraph{Custom let operators}
OCaml 4.08 allows me to define definitions for custom let operators. This is used to provide syntactic sugar for working with monads, and is similar to do-notation in Haskell. The reference documentation \footnote{\url{http://caml.inria.fr/pub/distrib/ocaml-4.08/ocaml-4.08-refman.html\#s\%3Abinding-operators}} specifies that a monad should provide a module which implements the (let*) and (and*) operators. The (let*) operator is the standard bind function - it takes the identifier bound to as the first argument to the function in bind. The (and*) operator is the product operation, it takes two monads and returns the monad product of the arguments - it has signature \texttt{'a m -> 'b m -> ('a * 'b) m}, where m is the monad type. An example, using the Option monad is given below to show the transformation that takes place. This feature allows the user to not have to use the bind (often aliased by >>=) or product functions explicitly, and offers a more intuitive syntax.

% TODO: add text within frame
\begin{figure}[!htb]
  \centering
  \begin{minipage}{0.45\textwidth}
    \centering
    \ocamlcode[label={New Syntax}]{code_snippets/old_monad.ml}
  \end{minipage}
  \begin{minipage}{0.45\textwidth}
    \centering
    \ocamlcode[label={Old Syntax}]{code_snippets/old_monad.ml}
  \end{minipage}
  \captionof{listing}{New let syntax which makes monadic binds easier to express}
\end{figure}

\subsection{Modules}
The module system is a key feature of the OCaml language. Every function in OCaml is in a module, by default the name of the file it resides in. Modules can also have signatures, which define what code is visible to a user, and constrain the module. Modules can hide types and implementations to provide a clean API, and are often used to wrap a particular type, for example a list or map. This means that to create or manipulate that type, the user must go through the module's API, ensuring only permitted operations are carried out. This is a feature I've used in designing distribution types. Modules can also be dynamically created from other modules, using functors, which are functions from modules to modules. This technique is used extensively in the Core library, and it allows modules to be customised and extended.

In OCaml, the module language (functors, modules, signatures, etc.) and the core language (functions, values, types, etc.) are considered separate, and values can't contain modules. First class modules provide a way around this constraint, and modules can be used in much the same way as ordinary values. This means a library can define functions to create modules which can then be used by other functions.

\subsection{Owl}

Owl is a scientific computing library written for OCaml \cite{owl}. It contains functions for working with a wide variety of probability distributions, e.g. normal, beta, binomial, etc. In particular, it is important to be able to find the probability density function (pdf) of distributions and to efficiently sample from distributions - these are the functions needed to perform inference. The distributions available in Owl form the primitive distributions I support, and are the building blocks of a probabilistic model.

Owl also provides many efficient helper functions, which can be used to calculate statistics over arrays of samples. Another important feature of Owl is the plotting API for which I wrote a wrapper to easily visualise output distributions from my PPL.

%% PREPARATION

\section{Probabilistic Programming}
Probabilistic programming is a programming paradigm where statistical models can be written as code and analysed. Models are a collection of random variables and the relationships between them.

Existing PPLs take two main forms - they can be standalone or embedded in another language. Standalone languages have their own syntax and compiler, so can be fine tuned to the task of inference, but often lack features since they have to be built from scratch. Embedded languages can utilise facilities in their host language, such as type checking, compilers or libraries, as well as allowing programs to be integrated into existing systems easily. However they need to work around the syntax and semantics of the host language.

The other main trade-off made in the design of PPLs is the range of models that can be expressed in the language against the efficiency of inference. Many languages restrict the set of allowed models in order to use more efficient inference algorithms which can take advantage of the restricted structure of models. Universal languages can represent any model, but suffer from less predictable inference procedures since many properties of the model (such as the number of random variables) are not available at compile-time. Overall, the more general models that need to be supported, the less efficient inference is.

There are two main approaches to building PPLs. One approach is graph-based, where a finite graph representing the variables and their relationships is generated from a program, over which efficient inference can take place. This approach is used in languages such as Infer.NET or JAGS, and has the benefit of being able to process high-dimensional data well, since efficient computation graph frameworks can be leveraged - another example is Edward \cite{edward}, which uses TensorFlow as a backend. This approach restricts the types of models to those that can be represented by the underlying graph.

Another approach, taken by the PPLs such as Anglican or WebPPL, is trace-based. This approach considers execution traces, with a `trace' being one run of a program, where the intermediate random variables take a particular value. Inference algorithms reason about these traces in order to produce a posterior distribution. A trace-based approach can lead to more models being able to be expressed, since we are not limited by the constraints of a graph. However, inference is often slower, since inference algorithms need to be more general purpose, and often converge slower. I have taken a trace-based approach in OwlPPL in order to allow my language to represent models which uses regular OCaml language constructs.

\subsection{Bayesian Inference}
Inference is the key motivating feature of probabilistic programming, and is a way to find a distribution over some input parameters based on the data we observe. The main feature of Bayesian inference is that we assign every model some prior belief. Often this prior is chosen based on our knowledge of the problem, but the prior can also be uninformative. The goal of Bayesian inference is to calculate the posterior distribution, which can be represented by Bayes' formula,
%
\[P(\theta\mid x)=\frac{P(x\mid\theta)P(\theta)}{P(x)}\propto{{P(x\mid\theta)P(\theta)}} \]
%
with $P(\theta)$ being the prior, and $P(x\mid \theta)$ being the likelihood model we define - the probability of observing the data given some parameters $\theta$. Both $x$ and $\theta$ are often vectors of variables, representing multiple parameters and observations respectively.

Unfortunately, exact Bayesian inference is usually computationally infeasible, especially when the number of random variables  we consider is large. The main issue is computing the normalising factor $P(x)$,
\[P(x)=\int_{\Theta}P(x,\theta)~d\theta\]
This represents marginalising $x$ out of the joint distribution by summing over all possible values of $\theta$. If the state space becomes very large (or infinite), or if $\theta$ is a very large vector, computing this exactly is intractable. For some distributions, this integral does not even have a analytic solution.

In the PPL setting, the prior is the generative model we define and conditioning statements define the likelihood model. Running the program forward without inference produces samples from the prior. Running inference on the program produces a new distribution, the posterior. Since the exact distribution usually can't be computed, inference algorithms I implement return distributions which can only be sampled from. Other statistics (e.g., mean, pdf, etc.) can then be estimated by taking a large number of samples.

\subsection{Inference Algorithms}
% https://ermongroup.github.io/cs228-notes/inference/sampling/
% https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/lectures/lecture17.pdf

% https://www.cs.ubc.ca/~fwood/teaching/OXWASP_CDT/probabilistic_programming.pdf
% http://www.robots.ox.ac.uk/~fwood/anglican/assets/pdf/Wood-AISTATS-2014.pdf

Inference algorithms are ways to systematically generate samples from posterior distributions given a likelihood function and a prior distribution. In trace-based PPLs, a model consists of latent (internal) variables and observed variables, and a single execution of a model (a program) can be thought of as an assignment to each of these variables, known as an \textit{execution trace}. This can be defined mathematically as below, by Bayes' rule:
%
\begin{equation} \label{eq:trace}
  p(x_{1:N}\mid y_{1:N})\propto \tilde{p}(y_{1:N},x_{1:N})
\end{equation}
%
Note that the trace may have a different number of variables each time a model is run, due to the fact that we allow general models which allow for unbounded recursion.

In \eqref{eq:trace}, $p$ is the posterior distribution of a particular trace $x$, given the observed variables $y$. This is proportional to the joint distribution of all the variables ($\tilde{p}$). The aim is then to find the posterior over the latent variables we are interested in (by marginalising out the other variables). We can specify which variables we care about within the program, either as part of the model, or outside it in a query to the model.
% TODO: put in equation of marginalissation, explain marginalisation more.

In general, there are two classes of inference algorithms - static and dynamic \cite{gordon2014probabilistic} which correspond roughly to graph-based and trace-based PPLs respectively. In static methods, the program is compiled to a static structure (e.g. a Bayesian network), which is analysed for inference to be performed. These methods generally constrain the models that can be represented (often to finite graphical models). Since my PPL aims to be universal, I focused mainly on dynamic methods, which use sampling to run programs and use conditioning statements that occur on these runs to perform inference.

\subsubsection{Exact Inference}

Exact Inference is the simplest method of calculating the posterior, but is usually computationally intractable. It involves calculating Bayes formula exactly, of which calculating the normalising constant is usually the problem. For discrete posterior distributions it can be thought of as calculating the probability of every possible value of the variable of interest. Since a random variable will be dependent on several others, this involves enumerating every possible combination of these variables and their outcomes.

\subsubsection{Rejection Sampling}

Since exact inference is too difficult in practice, we usually have to resort to \textit{Monte Carlo} \cite{monte-carlo} methods which rely on repeated sampling to infer properties of a distribution.

One such method, rejection sampling, is a very simple inference method which uses a `proposal' distribution which \textit{can} be sampled from. We take samples from the proposal distribution, and either accept or reject them. How likely we are to accept or reject a sample depends on the pdf of this proposal distribution. It can be shown that samples taken using this method converge to the required distribution \cite{flury1990acceptance}.

\subsubsection{Importance Sampling}

Importance sampling is another simple method improving on rejection sampling. It also uses a proposal distribution that can be sampled from. We calculate the ratio of the likelihoods between the two distributions to weight samples from the proposal. From doing this repeatedly with multiple samples from the proposal, we can build a posterior represented by a set of weighted samples.

\subsubsection{Monte Carlo Markov Chains (MCMC)}

MCMC methods involve constructing a Markov chain with a stationary distribution equal to the posterior distribution. A Markov chain is a statistical model consisting of a sequence of events, where the probability of any event depends only on the previous event. The stationary distribution is the distribution over successive states that the chain converges to (if it converges to one).

There exists several algorithms for finding this Markov chain, for example Metropolis-Hastings. Several MCMC algorithms require that we have a function, $f(x)$, which is proportional to the density of the distribution. The function is easy to compute for the posterior, since it is simply the prior multiplied by the posterior - the normalising constant can be ignored since we only need a proportional function.

MCMC algorithms have the same basic structure - to first `run' the chain for a burn-in period, taking samples and discarding them. Then, running the chain and collecting the states visited as samples. This set of samples is then a set of samples from the posterior, since the posterior should be equal to the stationary distribution. An important trade-off is made in the length of the burn-in period - too long and time is wasted discarding states, but too short and the chain will not converge to the correct distribution.

\subsubsection{Sequential Monte Carlo (SMC)}

SMC methods are algorithms which are based on using large numbers of weighted samples (`particles') to represent a posterior distribution. SMC methods are also known as particle filters. A particle is a value paired with an unnormalised weight which represents the likelihood of that value in the distribution. These particles are updated when data is observed and re-sampled from in order to converge the set of particles to the posterior.

For a set of weighted particles,
\[{\{(x^{[i]}, w^{[i]})\}}_{i=1..N}\]
%
the pdf of this distribution is given by
%
\[
  p(x) = \sum_{i=1}^{N}w^{[i]}\delta_{x^{[i]}}(x)
\]
where $\delta$ is the Dirac distribution.

The simplest SMC algorithms are particle filters \cite{particlefilter}, which simply resample particles on encountering new data, updating the weights of the particles based on how likely this data is deemed to be. However, many variations exist - the resampling method, updating the weights and the initialisation of particles can all be varied. The common feature of SMC algorithms is that they sequentially create sets of particles which converge to the desired distribution.

\subsubsection{Particle Monte Carlo Markov Chain (PMCMC)}
% TODO: pros/cons of all these?
SMC methods can also be combined with MCMC methods. These algorithms are known as particle Monte Carlo Markov chain (PMCMC) algorithms, and were first introduced for probabilistic programming in the Anglican language \cite{anglican-smc}. PMCMC methods are essentially MCMC algorithms which use an SMC algorithm as a proposal distribution.

\section{Professional Practice}

I adopted several best practices in order to ensure the project was successful. This includes performing regular testing, splitting code into separate modules designing signatures first, and ensuring my code follows a consistent style\footnote{\url{https://opensource.janestreet.com/standards/}}.

\subsection{Testing} \label{sec:prep-testing}
% google "unit testing probabilistic functions"
% google "unit test mcmc sampler"
% https://discourse.mc-stan.org/t/advice-for-testing-probabilistic-code/9451
The statistical nature of my library makes it difficult to write thorough unit tests for inference and sampling procedures. Ensuring posterior samplers are correct is a difficult problem due to inherent randomness, and the solutions to this I implemented are covered in section \ref{sec:impl-testing}.

Despite this, there is a suite of unit tests for individual deterministic functions. This is especially important for deterministic helper functions which should always work the same way, and unit tests allow regressions to be caught. I also used the \texttt{Quickcheck} library to perform some unit tests, which allows me to ensure certain invariants are preserved by automatically testing on many randomly generated inputs. I use the \texttt{bisect\_ppx} library to produce code coverage reports to ensure I am thoroughly testing code.

%% IMPLEMENTATION

\section{Language Design}
% specify DSL here
I chose to implement my language as a domain specific language (DSL), shallowly embedded into the main OCaml language. Using a shallow embedding means we can use all of the features of OCaml as normal, including branching (if/then/else), loops, references, let bindings, (higher-order) functions, and recursion. This has the benefit of leveraging OCaml features such as type checking, as well as permitting library code to be included directly within models.

Using a shallow embedding allows for recursively defined models. This can allow non-terminating (and therefore invalid) models to be defined. However, we can write functions which are \textit{stochastic recursive} \cite{siegmund}, that is, functions which have a probability of termination that tends to 1 as the number of successive calls tends to infinity. This leads to functions which terminate their recursion non-deterministically. Any model which does not satisfy this will be considered an invalid model - unfortunately as it is not possible to determine whether or not a program will halt, this property cannot be enforced.

An embedded PPL can be thought of as being the same as the host language, except for two extra operators:
\begin{itemize}
\item sample - for taking a sample from a distribution, either a primitive distribution or another (sub-)model.
\item condition - for conditioning on observations, defines how likely data observed is (also called observe or score in other PPLs).
\end{itemize}
The problem of designing a PPL is then finding a way to model the nondeterminism in the sample operator and integrate the information from the condition operator to guide inference and the execution traces explored. Most universal PPLs use a feature that enables exploring subcomputations - the different execution traces. This can be done using continuation passing style (CPS) transformations, as in WebPPL and Church \cite{mobus2018structure,goodman2012church}, or algebraic effects as in Pyro \cite{bingham2019pyro}. In order to achieve a similar effect, I model conditional distributions as monads in OwlPPL, as in \cite{scibior2015practical}, and realise probabilistic programs as a GADT.

\paragraph{Log Probabilities}
Calculating probabilities can often lead to underflow, since it is common to multiply many small probabilities together. To avoid this, I use logs of probabilities internally and add logs where I would multiply the original probabilities. This behaviour can be changed by changing the \texttt{Prob} module used by the \texttt{Dist} module - the documentation for \texttt{Prob} is in appendix \ref{app:docs}.

\section{Representing Distributions}
In order to define my DSL, I use 3 different data structures to represent the different types of distribution I use:
\begin{itemize}
\item Input distributions - primitive distributions that are used to build models.
\item General probabilistic models - composed primitives conditioned on data.
\item Output distributions - empirical distributions built from a set of samples from a posterior.
\end{itemize}
\vspace{2mm}
\subsection{Primitive Distributions}
In PPLs, users build complex models by composing more simple elementary primitive distributions for which we have extra information such as exact equations and the ability to sample directly. These primitive distributions need to have a few operations defined on them, namely \texttt{sample, pdf, cdf, ppf} (inverse of cdf) and \texttt{support} (the set of values that a distribution can take). These are all standard properties of distributions, and are used to perform inference.

An extension goal achieved here is to allow users to define their own primitive distributions if they have not already been defined in the library. For example, I have not implemented the Poisson distribution as a primitive distribution, but you can imagine models which need to use the Poisson as a building block. To achieve this, the user simply has to write a function which takes the parameters of the distribution as arguments and return a first class module matching the primitive distribution signature. This technique also allows users to use modules that they may have already defined, and constrain them to the required signature for use in the PPL.

The type of a primitive distribution is
\begin{center}
  \mintinline{ocaml}| type 'a prim_dist = (module PRIM_DIST with type t='a)|
\end{center}
with the \texttt{PRIM\_DIST} signature defined as in Listing \ref{lst:prim-sig}.

% TODO: put these side by side instead
\begin{figure}[!htb]
  \begin{minipage}{0.5\textwidth}
    \ocamlcode{code_snippets/prim_sig.ml}
    \captionof{listing}{Signature of the module that primitive distributions must implement}
    \label{lst:prim-sig}
  \end{minipage}
  \begin{minipage}{0.5\textwidth}
    \ocamlcode{code_snippets/new_dist.ml}
    \captionof{listing}{Adding a new distribution as a primitive}
    \label{lst:new-dist}
  \end{minipage}
\end{figure}

% \begin{listing}[!ht]
%   \ocamlcode{code_snippets/prim_sig.ml}
%   \caption{Signature of the module that primitive distributions must implement}
%   \label{lst:prim-sig}
% \end{listing}

An example of this being used to add a new primitive distribution is given in Listing \ref{lst:new-dist}, for the specific case of the Poisson distribution. The \texttt{Poisson} distribution can now be used as other primitives are, e.g. in \texttt{observe} statements.

% \begin{listing}[!ht]
%   \ocamlcode{code_snippets/new_dist.ml}
%   \caption{Adding a new distribution as a primitive}
%   \label{lst:new-dist}
% \end{listing}

\subsection{General Probabilistic Models}
Statistical models are designed by the user to model a process they are interested in and are given as the input to inference procedures. They are built up from primitive distributions, and should be both composable (in order to build bigger models) and amenable to inference procedures.

\subsubsection{Probability Monad}

As mentioned in section \ref{sec:prep-monad}, monads are a natural way to represent composable probability distributions. They allow the output from one distribution (essentially a sample), to be used as if it was of the type that the distribution is defined over. Essentially, the \texttt{bind} operation allows us to 'unwrap' the 'a dist type to allow us to manipulate a value of type 'a. We must then use \texttt{return} to `wrap' the value back into a value of type 'a dist. The type signatures of these functions are below, with \texttt{m} being the monad type.
% \begin{noindent}
\begin{figure}[!htb]
  \centering
  \begin{cminted}{ocaml}
    val bind: 'a m -> ('a -> 'b m) -> 'b m
    val return: 'a -> 'a m
  \end{cminted}
\end{figure}
% \end{noindent}
Using monads also allows us to define several helper functions which can be used when working with distributions. For example, we can `lift' operators to the \texttt{dist} type, for example allowing us to define adding two distributions over integers or floats using liftM or liftM2. We can also fold lists of distributions using a similar technique.

Using monads also allows the use of the extended let operators introduced in OCaml 4.08. These allow the definition of custom let operators, which mimic do-notation in Haskell. This means that sampling from a distribution (within a model) can be done using the \texttt{let*} operator, and the variable that is bound to can be used as if it were a normal value. The one caveat is that the user must remember to \texttt{return} at the end of the model with whatever variable(s) they want to find the posterior over. The \texttt{and*} operator can also be used when we use several independent distributions in a row. This can make for more efficient sampling (and inference) since more structure is encoded. It is also a common pattern to set up a model by first independently drawing from several distributions, as below.

% \begin{noindent}
\begin{listing}
  \begin{ocamlcode-in}
    (* two independent draws from standard normals *)
    let* x = normal 0. 1.
    and* y = normal 0. 1. in
    (* ...rest of model  *)
    return (x + y)
  \end{ocamlcode-in}
  \caption{Use of \texttt{and*} for independent draws}
\end{listing}
% \end{noindent}

I define my own functor for monads in order to automatically generate several helper functions. This takes a module with the basic monad functions and extends it with helper functions defined in terms of return and bind. The full module documentation for this can be found in appendix \ref{app:docs}. An example is the liftM2 function, which allows normal operations to be lifted to distributions, e.g. an addition operator for the output for two distributions can be simply created by lifting the normal addition operator, allowing distributions to be naturally `added'.

% \begin{noindent}
\begin{listing}
  \begin{ocamlcode-in}
    let ( +~ ) = liftM2 ( +. )
    (* the distribution of the sum of 2 independent draws from standard normals *)
    let d = (normal 0. 1.) +~ (normal 0. 1.)
  \end{ocamlcode-in}
  \caption{Lifting addition to distributions}
\end{listing}
% \end{noindent}

However, there are many different underlying data structures which can be used to represent distributions which conform to the definition of a monad. The simplest is a list of pairs representing a set of values and corresponding probabilities, \texttt{('a * float) list}. This is a natural way to represent discrete distributions, with return and bind defined as in Listing \ref{lst:monad_plist}. Here, \texttt{return} gives us the distribution with just one value, and bind combines a distribution with a function that takes every element from the initial distribution and applies a function that creates a set of new distributions. The new distributions are then flattened into a single list and normalised. This approach has been used to create functional probabilistic languages \cite{erwig}, but has several drawbacks, primarily the fact that it cannot be used to represent continuous distributions, and that inference is not efficient - there is no information from the model encoded in this representation, such as how random variables are combined or from what distributions they came from.

\begin{listing}[!ht]
  \ocamlcode{code_snippets/probmonad_list.ml}
  \caption{Probability monad as a List}
  \label{lst:monad_plist}
\end{listing}

Another issue is that flattening distributions is inefficient since duplicate values must be combined, and this approach is $O(n^2)$ when using a list since we scan up to the length of the entire list for every element. A better option is to use a map, which is provided in Core, and implemented as a balanced tree, significantly improving the time complexity of combining distributions.

\begin{listing}[!ht]
  \ocamlcode{code_snippets/probmonad_map.ml}
  \caption{Probability monad as a map}
  \label{lst:monad_pmap}
\end{listing}

Although this is not the final data structure I chose for general probabilistic models, it is the one I used for discrete empirical distributions.

\subsubsection{GADT} \label{sec:gadt}

The structure that I selected to represent general models is a generalised algebraic data type. GADTs are often used to implement interpreters in functional languages, and have been used to represent probabilistic models. The GADT I implement here (and some inference algorithms) is based on (Scibior et al. 2015) \cite{scibior2015practical}. This represents a model in a very general way, and can then be `interpreted' by a sampler or an inference algorithm. For sampling, I traverse the model, ignoring conditionals to enable forward sampling from the prior.

For inference, I provide some inference functions as transforming conditional distributions to distributions without any conditional statements, allowing sampling to be performed as normal. Some inference functions are also implemented by generating an empirical distribution that can be sampled from similarly.

Listing \ref{lst:gadt1} shows each of the variants. The monad functions are also provided, which construct the corresponding variants in the GADT - \texttt{Return} represents a distribution with only one value, and \texttt{Bind} contains a distribution and a function, which represents that function being applied to the output from that distribution, and is also bound to \texttt{(let*)}. The product function is used for models with independent sub-parts, such as drawing samples from many independently distributed variables, and could be used to parallelise models. The \texttt{Independent} variant is also bound to \texttt{(and*)}.

Primitive distributions have a variant which takes the primitive distribution type. We can find the exact pdf/cdf of these distributions, unlike the more general \texttt{dist} type, which can only be sampled from.

The \texttt{Conditional} variant is used to assign scores (likelihoods) to execution traces, and contains a function which takes an element produced by a model and returns a score for the corresponding trace. I define several wrappers over this variant to represent different types of conditioning, outlines in section \ref{sec:condition}.

\begin{listing}[!ht]
  \ocamlcode{code_snippets/gadt.ml}
  \caption{Representing a probabilistic model using a GADT}
  \label{lst:gadt1}
\end{listing}

An important feature of this type is that it is polymorphic - this allows distributions to be defined over any type, including arbitary ADTs or even distributions themselves.

\subsection{Empirical Distributions}

The output of Bayesian inference is a probability distribution over the variables we are interested in. Ideally, we would be able to produce an exact posterior distribution, and be able to extract exact relevant statistics. However, approximate inference only allows us to create functions to sample from this posterior. We can define a signature for a type of an empirical distribution that is created from posterior distributions by taking many samples. This can then be used to calculate useful statistics - e.g. mean, variance, pdf, cdf, etc.. The type is abstract to allow different implementations for discrete and continuous distributions.

For discrete distributions, I use a \texttt{Core.Map}\footnote{\url{https://ocaml.janestreet.com/ocaml-core/latest/doc/base/Base/Map/index.html}}, with the keys being the values that the distribution can take and the values the number of samples with that value. Continuous distributions use a dynamically resizing array - adding each sample is then $O(1)$ amortized, and statistics can be calculated using Owl's functions that operate on arrays. A constraint on continuous distributions of this type is that they are defined over floats, and only represent one dimension.
% Creating values with these types required passing a first class module representing the type of the keys - this is so that an appropriate compare function can be used in the internal tree data structure.

% I also provide modules which are backed by the polymorphic versions of these data structures (\texttt{Core.Map.Poly}). These types don't require the use of first class modules to create objects, since the keys are compared using the polymorphic compare function. While this makes using the module simpler to use (no need to pass the first class module), it also makes them more inefficient due to the use of polymorphic comparison.

\begin{listing}[ht]
  \ocamlcode{code_snippets/empirical_sig.ml}
  \caption{Signature for empirical distributions}
  \label{lst:empirical}
\end{listing}

The signature in Listing \ref{lst:empirical} is implemented for both continuous and discrete distributions. For the continuous case, I perform binning to approximate the continuous distribution by a discrete one in order to approximate the pdf. The number of bins used is calculated automatically from the number of samples taken.

\section{Conditioning} \label{sec:condition}

The GADT described in section \ref{sec:gadt} can be used to describe general models, in particular conditional distributions, thanks to the \texttt{Conditional} variant. Without this variant, we can only define prior distributions, but including it means we can incorporate observed data into our models and perform inference.

% https://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2017thesis.pdf - section on conditioning, pg.42
The condition variant in my GADT is used to assign scores to traces, and takes a function which takes an element and returns a float, a `score'. This score represents how likely the current trace is, given the value passed to the function. In this way, we can represent observations.

I have also implemented a few helpers to make it easier to condition models. The three main helpers are \texttt{condition}, \texttt{score} and \texttt{observe}, which are all specific cases of the general \texttt{Condition} variant.

The \texttt{condition} operator is used for hard conditioning, which conditions the model on an observation being true. If true is passed in, then the score assigned is 1, and if false, the score assigned is 0. This score represents how likely it is for the current trace to occur, and different inference algorithms will use this information to produce a distribution over all possible traces. We can use this operator to constrain certain variables or outcomes in a model. For example in Listing \ref{lst:dice}, we roll two dice and observe that the sum is 4 - we can then find the distribution over the first die (which won't include 4,5 or 6 since they are >=4).

This function is mostly useful for discrete models when using equality in this manner, since the probability of observing any given value in a continuous distribution is zero. However, if we are dealing with ranges, then we can use hard conditioning as in Listing \ref{lst:half_normal}, which constrains the standard normal distribution to be positive.

\begin{figure*}[!htb]
  \begin{minipage}{0.5\textwidth}
    \ocamlcode{code_snippets/dice_conditioning.ml}
    \captionof{listing}{Hard conditioning for discrete model}
    \label{lst:dice}
  \end{minipage}
  \begin{minipage}{0.5\textwidth}
    \ocamlcode{code_snippets/half_normal.ml}
    \captionof{listing}{Hard conditioning for continuous model}
    \label{lst:half_normal}
  \end{minipage}
\end{figure*}

For soft conditioning, for example an observation that we know comes from a certain distribution, there is an \texttt{observe} function. This function is essential for continuous distributions, since the probability of observing any one value is 0, making hard conditioning redundant since it will just assign a score of zero to every trace. Instead, we can use the pdf of the distribution to determine how likely that observation is in the model.

The \texttt{score} function is similar to the condition operator, except instead of 0, it assigns a particular constant score to the trace. This is generally used in a branching statement, where a constant score will be assigned depending on some (deterministic) condition.

% \begin{noindent}
\begin{listing}[!htb]
  \centering
  \begin{ocamlcode-in}
    let condition b d = Conditional((fun _ -> if b then 1. else 0.), d)
    let score s d = Conditional((fun _ -> s),d)
    let observe x dst d = Conditional((fun _ -> Primitive.pdf dst x),d)
  \end{ocamlcode-in}
  \caption{The definitions of the different conditioning operators}
  \label{lst:cond}
\end{listing}
% \end{noindent}

\section{Forward Sampling}
% https://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2017thesis.pdf - sec 7.1, pg 135
The simplest operation to define on models is to sample from them. Sampling from conditional distributions requires inference, and is discussed in section \ref{sec:inference}. Here, we run a probabilistic program 'forwards', that is, running a generative model and seeing the outputs without conditioning on observed data.

In PPLs, a complete program is a posterior distribution of a parameter given some observed data, $P(\theta\mid x)$. The generative model, i.e. the program without condition statements, is the prior distribution, $P(\theta)$. The condition statements then define the likelihood model, $P(x\mid \theta)$, the probability of the observations in the current model. So sampling from the prior is the same as sampling normally, but ignoring the conditionals (essentially ignoring the data).

We can also take into account the conditionals, and produce weighted samples, with the weight being the score assigned by each conditional branch, accumulated by multiplying all the scores. This gives us a set of values with corresponding weights which represent how likely those values are. An important property of these weights is that they are not normalised, so we cannot use them to find the posterior directly. I have implemented several variants of functions for finding the prior and sampling, all with the same concept as Listing ref{lst:sampling}.

\begin{listing}[!htb]
  \centering
  \ocamlcode{code_snippets/prior_sample.ml}
  \caption{Sampling functions}
  \label{lst:sampling}
\end{listing}

The function for generating a prior does not directly take samples, but manipulates the structure of the dist GADT. For example, in the \texttt{Bind} branch, it actually introduces 2 new bind variants (via \texttt{let*}) which produces a new distribution lazily. This makes it easier to use the prior within inference algorithms, and allows it to be composed with other distribution modifying functions.

\section{Implementing Inference} \label{sec:inference}

Inference is the key motivation behind probabilistic programming. Up to this section, I have discussed how to represent models but not do anything with them that couldn't be done in a standard language. With inference, we can produce a sampler which will accurately reflect a posterior distribution.

Inference can be thought of as a program transformation \cite{scibior2015practical, Zinkov2016ComposingIA}. In my ppl, this corresponds to a function of type \texttt{'a dist -> 'a dist}. This method allows for the composition of inference algorithms, exemplified in section \ref{sec:pimh}.

% use equations from here: https://arxiv.org/pdf/1507.00996.pdf

% Since I have used a trace-based approach, we can characterise the posterior probability of a trace as (from the previous chapter):
% % https://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2017thesis.pdf - pg.52
% $$p(x_{1:N}|y_{1:N})\propto\tilde{p}(y_{1:N},x_{1:N})$$

% We can now see how this formula corresponds to a program in my ppl. The example below is a very simple model, which adds two numbers drawn from discrete distributions, and observes a value.

% TODO: write example program, and relate to terms in formula

\subsection{Enumeration (Exact Inference)} \label{sec:enum}
Enumeration is the simplest way to perform exact inference on probabilistic programs, and essentially consists of computing the joint distribution over all the random variables in the model. This involves enumerating every execution path in the model, in this case performing a depth first search over the \texttt{dist} data structure. For every \texttt{bind} (i.e. every \texttt{let*}), there is a distribution ($d$) and a function from samples to new distributions ($f$). I call this function on every value in the support of the distribution $d$, and then enumerate all the possibilities. The final output is a \texttt{('a * float) list}, from which duplicates are removed and is then normalised, so that the probabilities sum to one.

\begin{listing}[ht]
  \ocamlcode{code_snippets/enumerate.ml}
  \caption{Enumerating all paths through a model}
  \label{lst:enum}
\end{listing}

This method is very naive, and therefore inefficient. Since we essentially take every possible execution trace, we do not exploit structure such as overlapping traces. This can be made slightly more efficient by using algorithms such as belief propagation \cite{belief-prop}, but they still only work on models made up from discrete distributions (and are not compatible with the way I represent models). Exact inference of this kind only works on models that can be represented as finite networks, and for Bayesian networks is in fact NP-hard \cite{cooper1990computational}. So instead, most of my project focuses on approximate inference.

\subsection{Rejection Sampling} \label{sec:rej}
% https://www.cs.ubc.ca/~schmidtm/Courses/540-W18/wood.pdf pg30
% Ancestral sampling, very good explanation of rejection
% Why rejection doesn't work for continuous, so must use importance instead -->
% http://www.cs.tut.fi/~elomaa/teach/AI-2013-9.pdf
% Hard rejection
In my implementation of rejection sampling, I take samples from the prior, with accumulated scores. If the score is above some constant threshold, then the sample is accepted, and rejected otherwise. The specific case of the general rejection sampling algorithm used here sets the proposal distribution as the prior, and we use the scores to approximate the density function of the posterior (Listing \ref{lst:rej}).
% todo: code of rejection sampling

\begin{listing}[!htb]
  \centering
  \ocamlcode{code_snippets/rej.ml}
  \caption{Simplest rejection sampling method}
  \label{lst:rej}
\end{listing}

This method is naive, since it runs an entire trace even if the first condition dropped the score below the threshold. An optimisation I implemented is to short-circuit this, and reject as soon as the trace goes below the threshold. It is also implemented as a dist transformation, so can again be used with the same sample methods.

This particular function is hard rejection, since samples with a lower score are always rejected. I have also implemented functionality to perform `soft' rejection. This method instead sets the probability of acceptance being the score attached to the sample.

A problem with rejection sampling is if conditions make most execution traces very unlikely, it will take a very large number of samples to have enough (or any) accepted samples. An example is given in Listing \ref{lst:bad-reject}, where the condition only has a 1\% chance of being true. This means that, on average, for every 1000 samples, we will only accept one.

% \begin{noindent}
\begin{listing}[!htb]
  \centering
  \begin{ocamlcode-in}
    let* x = bernoulli 0.001 in
    condition (x=0)
    (return x)
  \end{ocamlcode-in}

  \caption{An example of a model that is very inefficient under rejection sampling}
  \label{lst:bad-reject}
\end{listing}
% \end{noindent}
%
\subsection{Likelihood Weighting (Importance Sampling)} \label{sec:likelihood-wighting}
% http://www.cs.tut.fi/~elomaa/teach/AI-2013-9.pdf

Likelihood weighting is an importance sampling method, when the proposal distribution we use is the prior. We want any algorithm we use to be as general as possible, and not need to be tuned using auxiliary distributions chosen by hand. Since for any model we can find the prior distribution easily, it is natural to use this as a proposal distribution here - this can be seen in several of the implementations of inference.

The implementation of likelihood weighting is simple - we simply take a set of samples (with weights) from the prior, remove duplicates and normalise, and use this set of particles as a the categorical distribution representing the posterior.
% \begin{noindent}
\begin{listing}[!htb]
  \centering
  \begin{ocamlcode-in}
    let importance n d =
    let particles_dist = sequence @@ List.init n ~f:(fun _ -> prior d) in
    let* particles = particles_dist in
    categorical particles
  \end{ocamlcode-in}
  \caption{Likelihood weighting}
  \label{lst:imp}
\end{listing}
% \end{noindent}

The sequence function is a monad function that takes a list of distributions and fold them together so that they act as a single distribution returning entire lists. This allows the use of \texttt{(let*)} to sample a set of particles at once, and use them directly as the distribution.
% code of importance sampling.

\subsection{Metropolis Hastings (MCMC)} \label{sec:mh}
Metropolis Hastings is an MCMC algorithm, and so is used to find a Markov chain with the stationary distribution equal to the target distribution, here the posterior. There are many variants of this algorithm, and the one I implemented is the independent metropolis hastings (IMH) algorithm. I use the prior as a proposal distribution, using scores as an approximation to a density function. The algorithm is outlined below.

\begin{itemize}
\item Let $\pi$ be the target distribution that we want to sample from.
\item Let $q$ be the density function of the prior, approximated by the scores.
\item Initialise by taking a sample from the prior as the first state in the chain.
\item Let x be a sample from the prior.
\item Let y be the last state in the chain.
\item Calculate the acceptance probability, $\alpha(x,y)$ by \eqref{eq:accept}
  \begin{equation}
    \label{eq:accept}
    \alpha(x,y) =
    \begin{cases}
      \min{\left( \frac{\pi(y)q(x)}{\pi{x}q(y)},1 \right) } & \pi(x)q(x) > 0 \\
      1                                                     & \pi(x)q(x) = 0 \\
    \end{cases}
  \end{equation}
\item The state x is then accepted with probability $\alpha(x,y)$. If accepted, we use x as the next state, or if rejected, we re-use y as the next state.
\end{itemize}

This produces a Markov chain with transition probability: \[p(x, y) = q(y)\alpha(x, y) \quad\quad y\neq x\]
It is known as `independent' metropolis hastings (IMH) since subsequent candidate states ($x$) are independent of previous values of states.

% https://probmods.org/chapters/inference-algorithms.html
% MCMC section
I have implemented IMH as a function transforming distributions (\texttt{'a dist -> 'a dist}). This allows it to be composed with other inference algorithms, as well as allowing the standard sample function to be used on the output. To model a Markov chain, I use a \texttt{Core.Sequence.t} - which is a data structure for a lazy list. The constructor takes a function that takes a previous state to produce a new state and output a value - analogous to the transition function. In this case, the output is the same as the state.

\begin{listing}[H]
  \centering
  \ocamlcode{code_snippets/mh.ml}
  \caption{Metropolis hastings}
  \label{lst:mh}
\end{listing}

One important property of the return distribution is that consecutive sample statements will need to return different values (to simulate running the chain). In order to achieve this, I create some mutable state - the sequence, which will take a step every time sample is called on the output distribution. In order to make sure this sequence is persistent, I use a reference and put it after a bind (let*) statement, incrementing the chain every time the function is called (which is only on sampling). Since the bind statement contains a function, the reference is closed over and is persistent to the output distribution.


\subsection{Bootstrap Particle Filter (SMC)} \label{sec:pf}
% https://probmods.org/chapters/inference-algorithms.html
% particle filter section
Particle Filters are a class of algorithms which use particles to approximate a posterior. This is similar to the technique I used in importance sampling (\ref{sec:likelihood-wighting}), but the difference here is that the particles are sequentially updated as we observe condition statements (i.e. as we observe data). In fact, an example of an smc algorithm is sequential importance sampling, but here I use an algorithm called the bootstrap filter \cite{particlefilter}.

The code given in Listing \ref{lst:smc} transforms a conditional distribution to a new conditional distribution. In order to find the posterior, we simply ignore the conditional by finding the prior after using the smc method.

\begin{listing}[!htb]
  \centering
  \ocamlcode{code_snippets/smc.ml}
  \caption{Particle Filter}
  \label{lst:smc}
\end{listing}

The GADT is traversed top down, with particles being initialised at a `leaf' - primitives or returns. From this root, bind functions apply functions to the particles, and conditional statements updates the weights and resamples. The \texttt{resample} function takes a set of particles and takes samples from this set with replacement - this is the `bootstrap' resampling method. The output distribution is conditioned by the total weight of all particles.

Increasing the number of particles finds a more accurate distribution with a finer resolution, but also increases the amount of time and memory required.

\subsection{Particle Cascade (SMC)} \label{sec:pc}
The particle cascade algorithm (also asynchronous sequential Monte-Carlo) is an algorithm introduced in (Paige et al. 2014) \cite{paige2014asynchronous}, that extends the particle filter. It uses a lazily generated infinite set of particles, which allows it to be `anytime', that is, it can generate more particles without having to start regenerate a large particle set from scratch. It also features a parallelisable re-sample step, although I will not make use of this feature, since I am not using multi-core OCaml.

The main implementation difference is that instead of resampling, a particle `branching' operation is used, which produces a lazily generated set of particles at each resample step. Each particle produces 0 or more children to be used in the next iteration.

\subsection{Particle-Independent Metropolis-Hastings (PMCMC)} \label{sec:pimh}

SMC and MCMC algorithms are two distinct classes of algorithms, but can be combined to produce more efficient inference procedures. A simple example of these algorithms is the particle-independent metropolis-hastings algorithm \cite{pmcmc}. This algorithm first uses a particle filter to find an approximation of the posterior, then uses this approximation as a proposal distribution for Metropolis-Hastings.

Due to the fact that my PPL allows composition of inference algorithms, a basic implementation is very simple. However, this composition is only possible since the \texttt{smc} function produces a dist with conditionals, which no other inference method does.

% \begin{noindent}
\begin{listing}
  \begin{ocamlcode-in}
    let pimh k n d = mh k (Smc.smc n d)
  \end{ocamlcode-in}
  \caption{Particle-Independent Metropolis-Hastings}
\end{listing}
% \end{noindent}


\section{Visualisations}
Visualising the output distributions from inference can be done using the \texttt{Owl\_plplot} module, which allows plotting directly from OCaml, rather than having to interface with other programs manually. I have implemented several functions which simplify visualising distributions created by my PPL.

Empirical distributions are approximated by histograms displayed as bar charts using \texttt{Owl\_plplot}. For discrete distributions, this conversion is simple - each bar is simply the probability of the distribution at each value in the support. This is calculated by drawing $N$ samples, then for each value $x_i$, finding $\frac{n}{N}$, where $n$ is the number of samples that equal $x_i$, to find the approximate probability of that value in the distribution, $P(X = x_i)$. Discrete distributions can also have their cdf visualised as a step function.

\begin{figure}[!htb]
  \centering
  \subfloat[PDF]{{\includegraphics[width=0.4\textwidth]{figs/binompdf_hist.png} }}%
  \qquad
  \subfloat[CDF]{{\includegraphics[width=0.4\textwidth]{figs/binom_ecdf.png} }}%
  \caption{Samples from a binomial distribution visualised, $n=10,000$}
  \label{fig:vis-binom}
\end{figure}

Continuous distributions are also displayed as histograms, with a set of samples being put into $n$ equal width bins. The height of each bar is the pdf, which is calculated by finding the number of samples in each bin, then dividing by the total number of samples. To display the cdf, we can display the empirical cdf directly as a scatter plot, or join points to draw a step function.

\begin{figure}[!htb]
  \centering
  \subfloat[PDF]{{\includegraphics[width=0.4\textwidth]{figs/normpdf_hist.png} }}%
  \qquad
  \subfloat[CDF]{{\includegraphics[width=0.4\textwidth]{figs/norm_ecdf.png} }}%
  \caption{Approximate pdf and cdf of samples from a standard normal distribution}
  \label{fig:vis-norm}
\end{figure}

Other important visualisations for continuous distributions are the Q-Q and P-P plots. These provides a way to qualitatively compare distributions. P-P plots plot the cdfs of two distributions against each other, that is, for two cdfs $F$ and $G$, the points $(F(z), G(z))$ are plotted for some values of z in the range $(-\infty,+\infty)$. Q-Q plots plot the quantiles of both distributions - it uses the inverse of the cdfs (the ppf) to plot the points $(F^{-1}(q), G^{-1}(q))$, where $q$, the quantile, is in the interval $[0,1]$. This plots will generally use as many points as the data allows, and calculate the percentile for every data point available. For both plots, if all the points lie on the the line $y=x$, the distributions are identical. These plots are often used to find the differences between a theoretical expected distribution and the distribution given by the data. This can be used in the PPL context to find whether a distribution given by a model matches what was expected in the theory. Figure \ref{fig:vis-qq} shows the output of inference for a model that is expected to output a beta distribution (the coin model in section \ref{sec:coin}) - the points are close to the expected line, showing successful inference.

\begin{figure}[!htb]
  \centering
  \subfloat[Q-Q plot]{{\includegraphics[width=0.4\textwidth]{figs/qq.png} }}%
  \qquad
  \subfloat[P-P plot]{{\includegraphics[width=0.4\textwidth]{figs/pp.png} }}%
  \caption{Plots to compare inferred distributions with the exact solutions}
  \label{fig:vis-qq}
\end{figure}

For primitive continuous distributions, a smooth line can also be drawn since we have a function that can calculate the exact pdf or cdf. This can also be overlaid onto a histogram, to compare two distributions as in Figure \ref{fig:vis-samples}.

\begin{figure}[!htb]
  \centering
  \begin{minipage}{0.45\textwidth}
    \centering
    \ocamlcode{code_snippets/plotter.ml}
    % \captionof{listing}{Code to produce plot}
  \end{minipage}
  \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figs/coin_compare.png}
    % \captionof{figure}{Output}
  \end{minipage}
  %
  \caption{The approximate and exact pdf of the output of inference for a biased coin model, with code to produce plot}
  \label{fig:vis-samples}
\end{figure}


\section{Testing}\label{sec:impl-testing}

Testing systems which are inherently random can be tricky, as it is difficult to test behaviour that is expected to change from one execution to the next. For a PPL, the most important functions to test are inference procedures, and ensuring the posterior samplers that are returned are correct. The issue is that the sequence of samples generated will change every run.

One approach is to set a fixed random seed and make sure the same sequence of results are produced. The aim of a unit test, however, is to make sure that a desired property does not change from one version of the code to the next. The desired property here is that the samples fit a distribution, not that the same sequence is generated. For example, for sampling from $X \sim Bernoulli(0.5)$, we might observe true,false,true,false. However, the sequence of false,true,false,true would also satisfy the distribution (and be correct), but would fail the test. Even with a fixed random seed, a change in code may cause new outputs even though the desired statistical property hasn't changed.

Another approach is to perform a hypothesis test such as Kolmogorov-Smirnov \cite{massey1951kolmogorov}, to ensure distributions produced by my library are equal to what is expected. The alternative hypothesis is that the samples do not fit the distribution, and we aim to not accept this. A problem with tests of this kind is that they are expected to fail sometimes. There are two possible errors:
\begin{itemize}
\item \textit{Type 1 error} - false positive where we reject a true null hypothesis, equal to the significance level of the test.
\item \textit{Type 2 error} - false negative where we fail to reject a false null hypothesis.
\end{itemize}
In unit testing terms, tests will sometimes fail for functions that work, and sometimes succeed for functions that are subtly broken, so unit tests based on hypothesis tests will be flaky. In fact, since we expect these tests to fail a certain percentage of the time, if they do not sometimes fail there is a problem with our program.
% maybe put the type 1/type 2 error diagram here?

I decided to use hypothesis testing to evaluate my PPL's inference implementations, but did not build them into automated regression testing due to their flakiness. Instead, I used weaker unit tests for inference functions, testing that they could be applied to example models and produce samples without raising any exceptions. The only inference algorithm that could be unit tested thoroughly was the exact inference method, which is deterministic and always produces the correct (exact) posterior.

I wrote comprehensive unit tests for the deterministic functionality. The test framework I used, \texttt{Alcotest}, checks that outputs of functions match expected values. All the helper functions (e.g. normalise), the types which could be reliably created with the same values (e.g. empirical distributions), and simple distribution properties (e.g. sampling from a Dirac distribution always produces the same value) were tested.

I also used an additional library \texttt{Quickcheck}, to test that a specified invariant holds for a function - it uses randomly generated inputs to check a wide range of values. As an example (Listing \ref{lst:test}), for the normalise function, we expect that the output probabilities always sum to one, no matter the input array - Listing \ref{lst:test}.

% \begin{noindent}
\begin{listing}[!htb]
  \centering
  \begin{ocamlcode-in}
    let test_normalise_sum_to_1 =
    QCheck.Test.make ~count:1000 ~name:"test normalisation"
    QCheck.(list (pair int float)) (* type to randomly generate *)
    (fun l -> (List.sum ~f:snd (normalise l)) = 1.)
  \end{ocamlcode-in}
  \caption{Testing the normalisation function for particles}
  \label{lst:test}
\end{listing}
% \end{noindent}

A subset of the test output and code coverage are given in Figure \ref{fig:test-out}.

\begin{figure}[!htb]
  \centering
  \subfloat[Test report, abbreviated]{{\includegraphics[width=0.6\textwidth]{figs/tests.png} }}%
  \hfill
  \subfloat[Code coverage report]{{\includegraphics[width=0.35\textwidth]{figs/coverage.png} }}%
  \caption{Output from running unit tests}
  \label{fig:test-out}
\end{figure}

%% EVALUATION

\section{Evaluation}
\label{s:evaluation}

\textit{So far, I have developed a PPL that can be used to define arbitrary probabilistic models and perform Bayesian inference on them. To evaluate the performance of my PPL, I will present some examples to show programs written in my PPL and translated into equivalent programs in other PPLs, and then measure time and memory consumption of inference\footnote{All tests are carried out on a single core of an Intel\textsuperscript{(R)} Core\textsuperscript{(TM)} i5-7200U CPU @ 2.50GHz}. I will also determine the correctness of inference procedures on simple problems by using hypothesis tests to assert posterior samples fit the expected distribution.}

\section{Examples}
To show how my PPL would be used on real problems, I now outline a set of example problems. The first examples here are simple, and have analytic solutions - this is so that I can then test the correctness of applying inference on them. More complex realistic models are also included to test performance. Full derivations of the solutions as well as mathematical descriptions of the models are given in appendix \ref{app:examples}.

\subsection{Sprinkler}
% to show exact inference on discrete model
The sprinkler model is a commonly used example in Bayesian inference due to it's simplicity. It is an example of a \textit{Bayesian network}, and can be visualised as in Figure \ref{fig:sprinkler-network}. The code in Listing \ref{lst:sprinkler} shows the model in the diagram encoded as a program. This particular program models the probability of rain given that the grass is wet.

% \begin{noindent}
\begin{figure*}[!htb]
  \centering
  \begin{minipage}{0.47\linewidth}
    \ocamlcode{code_snippets/sprinkler.ml}
    \captionof{listing}{Sprinkler model in OwlPPL}
    \label{lst:sprinkler}
  \end{minipage}
  \begin{minipage}{0.47\linewidth}
    \includegraphics[width=\linewidth]{figs/sprinkler-network.png}
    \captionof{figure}{Sprinkler model as a network}
    \label{fig:sprinkler-network}
    \vspace{0.3cm}
    \begin{ocamlcode-in}
      let () =
      exact_inference sprinkler_model
      |> print_exact_bool
      (*false: 0.13706 true: 0.86294*)
    \end{ocamlcode-in}
    \captionof{listing}{Output of inference}
    \label{lst:inf-output}
  \end{minipage}
  % \caption{}
  % \label{}
\end{figure*}
% \end{noindent}

\subsection{Biased Coin} \label{sec:coin}
Modelling a biased coin shows an example of a very simple model with a continuous posterior that can be calculated analytically \cite{datasci}. The problem is that given a coin, we flip it 10 times and observe 9 heads. We not want to find out whether or not the coin is biased and with what weight (how likely is it to flip a heads). This model uses an uninformative prior, and the posterior over the weight of the coin is $\text{Beta}(10,2)$ (derivation given in \ref{app:coin})

The program in my PPL is shown in Listing \ref{lst:coin}, and demonstrates setting up the model, performing inference as well as finding the mean of the posterior. The application is to find the chance of the next coin flip landing heads.

\begin{listing}[!ht]
  \ocamlcode{code_snippets/coin.ml}
  \caption{Coin model - getting the mean of the posterior}
  \label{lst:coin}
\end{listing}


\begin{figure}[!htb]
  \begin{minipage}{0.5\textwidth}
    \centering
    \jscode{code_snippets/webppl/coin.js}
    \captionof{listing}{WebPPL}
  \end{minipage}
  \begin{minipage}{0.5\textwidth}
    \centering
    \clojurecode{code_snippets/anglican/coin.clj}
    \captionof{listing}{Anglican}
  \end{minipage}
  \caption{The coin model in WebPPL (JS) and Anglican (Clojure)}
  \label{fig:compare-coin}
\end{figure}

The comparison given in Figure \ref{fig:compare-coin} shows how the same model is defined in other languages. Both languages use similar constructs, despite differing syntax. This example also shows that my PPL is similar to existing systems, and is not more verbose.

\subsection{HMM}
Hidden Markov models are slightly more involved models, where we have a sequence of hidden states, which emit observed states. There are two distributions involved here, the transition distribution, which defines how likely the next state is given the current state, and the emission distribution, which is the distribution over the observed states given the hidden state. The example in Listing \ref{lst:hmm} uses discrete distributions, but any type of distribution can be used. The exact posterior for simple models can be found using the forward-backward algorithm, detailed in \ref{app:hmm}.
% use forward-backward to get exact posterior
\begin{listing}[!ht]
  \ocamlcode{code_snippets/hmm.ml}
  \caption{Hidden Markov Model}
  \label{lst:hmm}
\end{listing}

\subsection{Linear Regression}
This example shows how to use multiple data points to infer a continuous distribution. This example can be used to infer the parameters of a line through a set of 2-D points. The fold function can be used to condition on many observations easily. The fmap function is used to map outputs from a distribution. Since the linear regression model produces tuples of parameters, we can create individual distributions over either one. The comparison programs in other languages are given in \ref{app:linreg}.

\begin{listing}[!ht]
  \ocamlcode{code_snippets/linreg.ml}
  \caption{Linear Regression}
  \label{lst:linreg}
\end{listing}

\subsection{Infinite Mixture Model - Dirichlet Process}
This example demonstrates the common task of clustering a set of data points without knowledge of the number of clusters. This is a model which cannot be expressed in PPLs such as STAN or Infer.Net, since it is a non-parametric Bayesian model - we do not know the number of clusters beforehand. The infinite nature of this model requires the use of unbounded recursion and demonstrates the power of universal PPLs.

The prior for this model is a Dirichlet process \cite{teh2010dirichlet}, which defines a distribution over distributions. This model is a Dirichlet Process mixture model with an infinite number of Gaussians components \cite{dpmm}, and the number of clusters is allowed to grow with the dataset size. I use a mixture of Gaussians, meaning the likelihood of a point belonging to each cluster is given by different normal distributions.

\begin{listing}[H]
  \ocamlcode{code_snippets/dpmm.ml}
  \captionof{listing}{Infinite mixture model in OwlPPL, gets the cluster assigned to each data point}
\end{listing}


% Need to show examples which can't be done in graph based thing - maybe geometric somewhere
% Need to explain why these examples are actually difficult.
% http://www.cs.cmu.edu/~epxing/Class/10708-16/slide/lecture18-DP.pdf


\section{Statistical tests}
To evaluate the correctness of my PPL, I used statistical tests which measure goodness-of-fit, i.e. how similar two distributions are to each other. I compare the empirical distribution of 10,000 samples from an approximated distribution to an exact distribution which is calculated analytically. Test distributions (e.g. the $\chi^2$ distribution) were calculated using \texttt{Owl}, and functions to calculate the test statistics and p-values are given in the \texttt{Evaluation} module.

For all tests described below, I set the significance level $\alpha = 0.05$ and use null and alternative hypotheses as follows:

$H_0:$ The sample data follow the desired distribution\\
$H_1:$ The sample data do not follow the desired distribution

\subsection{Chi-squared}

The $\chi^2$ test is a simple goodness-of-fit test which can test discrete distributions. The test statistic is as follows, with each $i$ being a distinct element in the distribution, $x_i$ is the observed number of samples with the value $i$, and $m_i$ is the expected number of samples for the value $i$.
%
\[X^{2}=\sum _{i=1}^{k}{\frac {(x_{i}-m_{i})^{2}}{m_{i}}}\]
%
This test statistic is compared against the critical value (at the significance level) of the chi-squared distribution, with $k-1$ degrees of freedom , where k is the number of possible values of the distribution.

\subsubsection{Results}
\begin{table}[!ht]
  \centering
  % \csvautotabular{data/hypothesis/hypothesis-chi.csv}
  \pgfplotstableread[col sep=comma,]{data/hypothesis/hypothesis-chi.csv}\normal
  \pgfplotstabletranspose[colnames from = 0]\transpose\normal
  \pgfplotstabletypeset[
  every row/.style={/pgf/number format/sci},
  every head row/.style={before row=\toprule, after row=\midrule},
  every last row/.style={after row=\bottomrule},
  every col no 0/.style={
    string type,
    column name={Inference Method},
    column type={@{}l}},
  % column type={r},
  every col no 1/.style={
    precision=3,
    fixed zerofill=true,
    column type={c}},
  every col no 2/.style={
    column type={c@{}},
    precision=3,
    fixed zerofill=true
  },
  ]\transpose
  \caption{p-values of $\chi^2$ test on different models using different inference procedures}
  \label{tab:chi-pvals}
\end{table}

Table \ref{tab:chi-pvals} shows the results of carrying out the test on all inference procedures for the sprinkler and hidden markov models. All of the values are greater than 0.05, so we do not reject the null hypothesis in each case. Therefore we conclude that, at the 5\% significance level, the distributions are not significantly dissimilar.

\subsection{Kolmogorov-Smirnov}

The Kolmogorov-Smirnov test is a non parametric test which is used to compare a set of samples with a distribution - this is the one-sample K-S test. There is also a two-sample K-S test, which compares two sets of samples against each other. I use the one-sample test here to compare samples taken from the inferred posteriors to their exact analytic solutions.

The test statistic is as follows, with $F_n(x)$ being the empirical cumulative distribution of n samples, and $F(x)$ being the exact cumulative distribution.
\begin{align*}
  F_{n}(x) & =\frac{1}{n}\sum_{i=1}^{n}I_{[-\infty ,x]}(X_{i}) \\
  D_{n}    & =\sup_{x}|F_{n}(x)-F(x)|
\end{align*}
This test statistic is compared against the critical values of the Kolmogorov distribution, rejecting the null hypothesis if $\sqrt{n}D_n > K_\alpha$, where $K_\alpha$ is the critical value at the significance level $\alpha$, and $n$ is the number of samples.

\subsubsection{Results}

\begin{table}[!ht]
  \centering
  % \csvautotabular{data/hypothesis/hypothesis-ks.csv}
  \pgfplotstableread[col sep=comma,]{data/hypothesis/hypothesis-ks.csv}\normal
  \pgfplotstabletranspose[colnames from = 0]\transpose\normal
  \pgfplotstabletypeset[
  string type,
  % every col no 1/.style={precision=1}
  % every row/.style={/pgf/number format/sci},
  every head row/.style={before row=\toprule, after row=\midrule},
  every last row/.style={after row=\bottomrule},
  every col no 0/.style={
    string type,
    column name={Inference Method},
    column type={@{}l}},
  every col no 1/.style={
    column type={c@{}},
    precision=3,
    fixed zerofill=true
  },
  ]\transpose
  \caption{p-values of K-S test on different models using different inference procedures}
  \label{tab:ks-pvals}
\end{table}
Table \ref{tab:ks-pvals} shows that for the biased coin model, the p-value obtained from all tests are greater than then 0.05. This means we do not reject $H_0$ for any inference procedure, so we can be confident (at the 5\% significance level) that the inference procedures are correct. We can be more sure of some inference procedures, indicated by higher p-values. These results show that there is no significant difference between the generated posterior and the real solution.

\FloatBarrier

\section{Convergence of sampling}
I also used the KL-divergence metric to determine the (dis)similarity of two distributions. The formula for KL Divergence of discrete distributions $P$ and $Q$ is easy to calculate by \eqref{eq:kl_disc}
%
\begin{equation} \label{eq:kl_disc}
  {D_{\text{KL}}(P\parallel Q)=\sum _{x\in {\mathcal {X}}}P(x)\log \left({\frac {P(x)}{Q(x)}}\right)}
\end{equation}
%
The continuous version is similar, with $p$ and $q$ now being density functions as in \eqref{eq:kl_cont}.
%
\begin{equation} \label{eq:kl_cont}
  {D_\text{KL}}(P\parallel Q)=\int _{-\infty }^{\infty }p(x)\log \left({\frac {p(x)}{q(x)}}\right)\,dx
\end{equation}
%
% Since we cannot compute this integral exactly (we only have the exact density function for one of the distributions), I put the set of samples into discrete bins to approximate $q(x)$. I then used Monte Carlo integration to compute the integral.
Since I only have a set of samples from $q$, this integral can't be calculated exactly - there is no exact density function. However, there are ways to estimate density functions, as in (Perez 2008) \cite{perez2008kullback}. The first step is to approximate the cdf by finding the empirical cdf, $P_e$ \eqref{eq:pe} then linearly interpolating between points to produce a continuous function $P_c$ \eqref{eq:pc}. Estimating the derivative of $P_c$ then gives the pdf estimator, $\hat{P}$ \eqref{eq:phat}.
%
\begin{align}
  P_e(x)     & = \frac1{n}\sum_{i=1}^n U(x-x_i) ,        & \text{ where $U$ is the step function}\label{eq:pe}    \\
  P_c(x)     & = \begin{cases}
    0          & x<x_0                                                                                          \\
    a_ix+b_i   & x_{i-1} \leq x \le x_i                                                                         \\
    1          & x_{n+1} \leq x
  \end{cases} \label{eq:pc} ,& \text{$a_i$ and $b_i$ chosen to make $P_c$ continuous }\\
  \hat{P}(x) & = \frac{P_c(x+\delta) - P_c(x)}{\delta} , & \text{ for sufficiently small }\delta  \label{eq:phat}
\end{align}
%
The final estimator \eqref{eq:final_kl_est} is given by using the exact pdf of $q$ and performing Monte Carlo integration.
%
\begin{equation}
  \label{eq:final_kl_est}
  \hat{D}_{KL}(P \| Q) = \frac1{n}\sum_{i=1}^n \log\left(\frac{\hat{P}(x_i)}{q(x_i)}\right)
\end{equation}
%
Both the metrics (discrete and continuous) were computed with code written using the \texttt{EmpiricalDist} modules.

The idea behind conducting this test is ensuring that the KL divergence decreases as we take more samples from the posterior. This ensures that the solution converges to the correct distribution - a KL divergence of 0 implies the distributions are identical.

\begin{figure}[H]
  \centering
  \input{tikz/kl_plot.tex}
  \caption{Plot of KL-divergence with increasing number of samples for different models and inference procedures - average over 20 runs}
  \label{fig:kl}
\end{figure}

Figure \ref{fig:kl} shows the results of this test. For each inference procedure, we can see that the KL-divergence for each model generally decreases as we take more samples. Rejection sampling is consistently the worst performing inference procedure, with particle based methods such as the particle filter or importance sampling generating more accurate distributions. These plots have all been smoothed by taking a moving average in order to reduce the impact of noise.

\section{Performance}
% probabilistic c (Paige14) makes the same comparison
% TODO: measure performance with varying no. particles (measure KL with difference no. particles)

I evaluated the performance of OwlPPL against Anglican and WebPPL. All of these languages are universal PPLs embedded in different host languages, so are comparable to my PPL. I only compare the inference algorithms for which there are comparable implementations in the other languages.

Figures \ref{fig:time-perf} and \ref{fig:mem-perf} shows how my PPL compares against these languages for a range of models and inference procedures. All the models have been introduced previously, and have been shown to produce correct results in my PPL when using the given inference procedures. I measure both running time\footnote{timed using libraries in respective languages} and peak memory usage\footnote{computed using \texttt{time -f "\%M"}}. Here, smc refers to the particle filter implementation.

\begin{figure}[!ht]
  \centering
  \input{tikz/times_plot.tex}
  \caption{Time taken for inference against other languages for different models and inference algorithms, taking 10,000 samples from the posterior, averaged over 20 runs. Error bars show the 95\% confidence interval}
  \label{fig:time-perf}
\end{figure}

\begin{figure}[!ht]
  \centering
  \input{tikz/mems_plot.tex}
  \caption{Memory Usage of my PPL, compared against other languages for different models, all using an MCMC algorithm, taking 10,000 samples from the posterior, averaged over 20 runs. Error bars show the 95\% confidence interval}
  \label{fig:mem-perf}
\end{figure}

These graphs show that OwlPPL performs consistently better that WebPPL in both memory and time. There is also less variance in the performance of OwlPPL, except in the case of rejection sampling for the coin model.

OwlPPL slightly outperforms Anglican on the two continuous models for some algorithms (My implementation of rejection sampling performs poorly on continuous models, which is expected from my naive implementation), but is generally slower than Anglican for the discrete models. This may be because Anglican uses a more efficient representation for discrete distributions, and my representation may need to be optimised. Anglican is a Clojure library, which runs on the JVM, whereas WebPPL uses NodeJS, a JavaScript interpreter.  WebPPL may incur and interpretive overhead, explaining slower running times.

My PPL is significantly better than both Anglican and WebPPL in terms of peak memory usage. All three languages are garbage collected, but OCaml does not run code through a virtual machine, and native binaries are generated. This could explain the lower memory usage, with the overheads of the JVM and the node runtime dominating in those languages.

I also measured the running time of inference with increasing data used. I tested the linear regression model, increasing the length of the array used as input. Models which are conditioned on more data are expected to give more accurate results so it is desirable for inference to have low complexity.

My results show that running time increases linearly with the size of data. Figure \ref{fig:time-datasize} shows that all the inference functions run in time linear to the size of the input, but the constant factors vary substantially - for example, Sequential Monte Carlo has a much steeper gradient than Metropolis-Hastings, but both have the same shape. This also shows how some inference procedures take much more time than others, however, this often results in more accurate results. For example, the particle filter is slower than rejection sampling here, but Figure \ref{fig:kl} shows that the particle filter produces more accurate posterior distributions. I use a log y-axis here due to the wildly varying gradients of the functions - the curves shown map to lines on a linear axis.

\begin{figure}[!ht]
  \centering
  \input{tikz/linreg_by_datasize.tex}
  \caption{Time taken for inference as a function of input data length as the mean of 10 runs each taking 1,000 samples from the posterior, shaded areas are the 95\% confidence interval ($\pm 2\sigma$)}
  \label{fig:time-datasize}
\end{figure}

%% CONCLUSION

\section{Conclusion}
\label{s:conclusion}

In this project, I have designed, developed and tested a probabilistic programming language embedding in OCaml. It has achieved all the core requirements as well as some of the extensions. My PPL can represent a wide variety of models, including infinite models with unbounded recursion, fulfilling the definition of a universal PPL. Standard OCaml features, such as pattern matching or higher order functions, and well as existing deterministic functions can be used in my PPL. Models can then be combined in complex ways, and existing OCaml libraries can be used within models.

I have also performed extensive evaluation of my PPL, showing that the performance is competitive with other universal PPLs. In particular, the memory usage of OwlPPL proved to be significantly lower than other languages, which could make it appropriate for edge computing. In addition, performing hypothesis tests shows that my PPL produces correct results, and my implementations of inference procedures are very unlikely to be faulty, which is the best guarantee that can be given. Programs written in my PPL are also not overly verbose when compared to these languages.

Future work would mainly focus on how to improve inference. For example, there are several algorithms I have implemented that would benefit from the use of multiple cores - which may be possible with the ongoing development of multi-core OCaml. In particular, the Independent variant could benefit greatly from parallelisation.

I could also use more efficient inference algorithm implementations. This may require changing the core data structure or adding more variants to give more information, for example adding variable names in order to keep track of the primitives being used, or allowing a user to specify guide distributions for models to create more specific proposal distributions for MCMC (a technique used by several PPLs, including Pyro and WebPPL).

One of my initial goals was for my PPL to be able to represent as many types of model as possible. This prompted the use of a trace based approach (inspired by Church) rather than using a computation graph. However, there are recent universal PPLs which use dynamic computation graphs to make inference more efficient (e.g. Pyro). Since \texttt{Owl} contains a powerful computational graph implementation, this could be a further extension.

% \begin{acks}
% \end{acks}

{
  \clearpage
  \bibliographystyle{ACM-Reference-Format}
  \bibliography{owl-ppl.bib}
}

\appendix
\end{document}
