\documentclass[sigconf]{acmart}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
% \setcopyright{acmcopyright}
% \copyrightyear{2018}
% \acmYear{2018}
% \acmDOI{10.1145/1122445.1122456}

%% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[Woodstock '18]{Woodstock '18: ACM Symposium on Neural
%   Gaze Detection}{June 03--05, 2018}{Woodstock, NY}
% \acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%   June 03--05, 2018, Woodstock, NY}
% \acmPrice{15.00}
% \acmISBN{978-1-4503-XXXX-X/18/06}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
\acmSubmissionID{74}

\usepackage{subcaption}

\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepgfplotslibrary{groupplots}
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.13}

\usepackage{placeins}

\usepackage{pifont}
\definecolor{green1}{rgb}{0.0, 0.5, 0.0}
\definecolor{red1}{rgb}{1.0, 0.01, 0.24}
\newcommand{\cmark}{\textcolor{green1}{\checkmark}}%
\newcommand{\xmark}{\textcolor{red1}{\ding{55}}}%

\usepackage[outputdir=out, cache=false]{minted}
\setminted{fontsize=\footnotesize}
\newmintedfile[ocamlcode]{ocaml}{frame=single,framesep=7pt}
\newmintedfile[jscode]{js}{frame=single,framesep=7pt}
\newmintedfile[clojurecode]{clj}{frame=single,framesep=7pt}
\newminted[ocamlcode-in]{ocaml}{frame=single,framesep=7pt,autogobble}

\usepackage{xpatch,letltxmacro}
\LetLtxMacro{\cminted}{\minted}
\let\endcminted\endminted
\xpretocmd{\cminted}{\RecustomVerbatimEnvironment{Verbatim}{BVerbatim}{}}{}{}

\usepackage{xspace}

\newcommand\note[2]{\color{#1}\bf #2}
\newcommand\mort[1]{{\note{red}{mort: #1}}}
% \newcommand\mortl[1]{{\color{red} mort: \begin{itemize}#1\end{itemize}}}

\newcommand{\one}{({\em i})\/}
\newcommand{\two}{({\em ii})\/}
\newcommand{\three}{({\em iii})\/}
\newcommand{\four}{({\em iv})\/}
\newcommand{\five}{({\em v})\/}

\newcommand{\sampling}{\emph{sampling}\xspace}
\newcommand{\s}[1]{(\S\ref{#1})}

\newcommand{\pupil}{Pupil\xspace}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{
  \pupil, an Efficient Trace-Based, Type-Safe \\
  Probabilistic Programming Language
}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Anik Roy}
\authornote{Work carried out for final year undergraduate project.}
\affiliation{%
  \institution{Christ's College}
  \city{Cambridge University}
  \country{UK}
}
\email{anik545@gmail.com}

\author{Richard Mortier}
\affiliation{%
  \institution{Department of Computer Science \& Technology}
  \city{Cambridge University}
  \country{UK}
}
\email{richard.mortier@cl.cam.ac.uk}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Creating statistical models and performing inference on these models is key to data science. A probabilistic programming language (PPL) is a language for creating complex models by composing simpler models and probability distributions, separating inference from model specification, allowing inference to be performed automatically~\cite{gordon2014probabilistic}. We present \emph{\pupil}, a shallow embedded PPL in the OCaml language that leverages OCaml's expressive type system and efficient native code generation. We compare \pupil's performance to that of two well-known alternative PPLs, Anglican and WebPPL, We find that \pupil outperforms WebPPL in inference speed and is commensurate with Anglican, and in both cases uses substantially less memory, making it particularly appropriate for use in edge computing applications.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
% \begin{CCSXML}
%   <ccs2012>
%   <concept>
%   <concept_id>10010520.10010553.10010562</concept_id>
%   <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%   <concept_significance>500</concept_significance>
%   </concept>
%   <concept>
%   <concept_id>10010520.10010575.10010755</concept_id>
%   <concept_desc>Computer systems organization~Redundancy</concept_desc>
%   <concept_significance>300</concept_significance>
%   </concept>
%   <concept>
%   <concept_id>10010520.10010553.10010554</concept_id>
%   <concept_desc>Computer systems organization~Robotics</concept_desc>
%   <concept_significance>100</concept_significance>
%   </concept>
%   <concept>
%   <concept_id>10003033.10003083.10003095</concept_id>
%   <concept_desc>Networks~Network reliability</concept_desc>
%   <concept_significance>100</concept_significance>
%   </concept>
%   </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Computer systems organization~Embedded systems}
% \ccsdesc[300]{Computer systems organization~Redundancy}
% \ccsdesc{Computer systems organization~Robotics}
% \ccsdesc[100]{Networks~Network reliability}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
% \keywords{datasets, neural networks, gaze detection, text tagging}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
\label{s:introduction}

Creating statistical models and performing inference on these models is key to data science. Such modelling involves formulating a prior belief over some parameters ($x$), the generative model ($p(x)$), and a set of conditions ($p(y|x)$) which specify the likelihood of observed data given the parameters. The goal is then to find the posterior, the (inferred) distribution over the parameters given the data we observe ($p(x|y)$). As this is generally intractable, approximate methods are used -- but it can be difficult to disentangle the approximation method from the model, reducing re-usability of methods and robustness of implementation.

A probabilistic programming language (PPL) is a language for creating complex models by composing simpler models and probability distributions, separating inference from model specification, allowing inference to be performed automatically~\cite{gordon2014probabilistic}. This has numerous advantages: inference code is written and optimised once, independent of model; many different inference algorithms can be provided, suitable for different problems; and models can be written by domain experts, without concern for inference.~\s{s:related}

PPLs can be standalone languages or embedded into another language, giving access to the full power of the host language, making it easier to combine models. We present \emph{\pupil}, a shallow embedded PPL in the OCaml language that leverages OCaml's expressive type system and efficient native code generation. \pupil can represent a wide variety of models, not limited to finite graphical models or discrete distributions, and provides several inference procedures. Distributions are represented using a Generalised Algebraic Data Type (GADT) as a monad, allowing distributions to be combined type-safely to build models.~\s{s:pupil}

We show that \pupil's inference algorithms are correct using statistical tests on simple programs that can be solved analytically. We compare \pupil's performance to that of two well-known alternative PPLs, Anglican and WebPPL, We find that \pupil outperforms WebPPL in inference speed, and is commensurate with Anglican. In both cases, \pupil exhibits significantly lower memory usage making it particularly suitable for low-resource availability environments such as edge computing.~\s{s:evaluation}

\section{Related Work}
\label{s:related}

\begin{table}
  \centering
  \begin{tabular}{ l l c c l }
    \toprule
    \textbf{PPL}
    & \textbf{Host}
    & \textbf{Universal?}
    & \textbf{Continuous?}
    & \textbf{Year} \\
    \midrule

    BUGS~\cite{gilks1994bugs}
    & --- & \xmark & \cmark & 1994 \\

    IBAL~\cite{ibal}
    & OCaml & \xmark & \xmark & 2000 \\

    JAGS~\cite{plummer2004jags}
    & --- & \xmark & \cmark & 2004 \\

    Erwig~\cite{erwig}
    & Haskell & \cmark & \cmark & 2006\\

    Church~\cite{goodman2012church}
    & LISP & \cmark & \cmark & 2008 \\

    HANSEI~\cite{kiselyov2009embedded}
    & OCaml & \xmark & \xmark & 2009 \\

    Infer.NET~\cite{wang2011using}
    & F\# & \xmark & \cmark & 2011 \\

    STAN~\cite{carpenter2017stan}
    & --- & \xmark & \cmark & 2012 \\

    Anglican~\cite{anglican-smc}
    & Clojure & \cmark & \cmark & 2014 \\

    Edward~\cite{edward}
    & --- & \xmark & \cmark & 2017\\

    WebPPL~\cite{mobus2018structure}
    & JavaScript & \cmark & \cmark & 2018 \\

    Pyro~\cite{bingham2019pyro}
    & Python & \cmark & \cmark & 2019 \\

    \pupil
    & OCaml & \cmark & \cmark & 2020 \\
    \bottomrule
  \end{tabular}
  \caption{A selection of current PPLs, their host languages, and whether they are universal and support continuous distributions.}
  \label{tab:ppl-summ}
\end{table}

There are many examples of PPLs, both as DSLs embedded into other languages (including OCaml) and as standalone compilers. Standalone languages have their own syntax and compiler, so can be fine tuned to the task of inference, but often lack features since they have to be built from scratch. Embedded languages can utilise facilities in their host language, such as type checking, compilers or libraries, as well as allowing programs to be integrated into existing systems easily, but they must work around the syntax and semantics of the host language. Some early PPLs, such as BUGS~\cite{gilks1994bugs} or JAGS~\cite{plummer2004jags}, limited the types of models representable in the language to finite graphical models, where the model could be expressed as a static graph of random variables and their relationships.

Many languages restrict the set of allowed models in order to use more efficient inference algorithms which can take advantage of the restricted structure of models. Universal languages can represent any model, but suffer from less predictable inference procedures since many properties of the model (such as the number of random variables) are not available at compile-time. Restricting the types of possible models can lead to efficient implementations of inference algorithms. Languages such as STAN~\cite{carpenter2017stan} or Infer.NET~\cite{wang2011using} exploit this, and do not allow, for example, unbounded recursion when defining models.

PPLs which can express models that have an unlimited number of random variables (and so do not compile to a static graph) are known as `universal'~\cite{borgstrom2016lambda}, and include Church~\cite{goodman2012church}, WebPPL~\cite{mobus2018structure} and Anglican~\cite{anglican-smc}. These tend to be slower at inference due to the need to support a greater range of models. Some PPLs restrict the types of distribution allowed, for example HANSEI~\cite{kiselyov2009embedded} and IBAL~\cite{ibal} only allow discrete distributions.

There are two principle approaches to the implementation of PPLs. \one~Graph-based, where a finite graph representing the variables and their relationships, over which efficient inference can take place, is generated from a program, e.g,~Infer.NET~\cite{wang2011using} or JAGS~\cite{plummer2004jags}. It has the benefit of being able to process high-dimensional data well as efficient computation graph frameworks can be leveraged, e.g.,~Edward~\cite{edward}, which uses TensorFlow~\cite{tensorflow} as a backend. However, it does restrict the types of models to those that can be represented by the underlying graph. \two~Trace-based, where execution traces corresponding to each run of a program with intermediate random variables taki a particular value, are reasoned over by inference algorithms to produce a posterior distribution~\cite{anglican-smc,mobus2018structure}. This can lead to greater expressiveness as we are not limited by the constraints of a graph, but inference is often slower as more general purpose algorithms must be used.

Prior PPLs embedded in OCaml include IBAL~\cite{ibal} and HANSEI~\cite{kiselyov2009embedded}, and \pupil takes some inspiration from these particularly in implementation of efficient inference engines. A summary of several PPLs is given in Table \ref{tab:ppl-summ}.

\section{\pupil, an OCaml PPL}
\label{s:pupil}

\pupil is shallowly embedded in the OCaml language, and makes use of features such as its strong type-system to ensure programs that compile will run, algebraic datatypes to represent probabilistic programs as trees, and pattern matching to simplify interpretation and transformation of these trees. \pupil builds on Owl, a scientific computing library written for OCaml~\cite{owl} containing functions for working with a wide variety of probability distributions, as well as to find their probability density function (pdf) and to sample efficiently from them, the functions required to perform inference.

Using a shallow embedding means we can use all of the features of OCaml as normal, including branching (if/then/else), loops, references, let bindings, (higher-order) functions, and recursion. This has the benefit of leveraging OCaml features such as type checking, as well as permitting library code to be included directly within models. It also allows for recursively defined models, which can be non-terminating (and therefore invalid) models. However, we can write functions which are \textit{stochastic recursive}~\cite{siegmund}, that is, functions which have a probability of termination that tends to 1 as the number of successive calls tends to infinity. This leads to functions which terminate their recursion non-deterministically. Any model which does not satisfy this will be considered an invalid model, though the halting problem unfortunately means this property cannot be enforced.

The shallow embedding results in the provision of two operations to OCaml: \emph{sample}, for taking a sample from a distribution whether primitive or another (sub-)model; and \emph{condition}, for conditioning on observations, defining how likely is observed data (called \emph{observe} or \emph{score} in other PPLs).

The problem of designing a PPL is then finding a way to model the nondeterminism in the sample operator and integrate the information from the condition operator to guide inference and the execution traces explored. Most universal PPLs use a feature that enables exploring subcomputations - the different execution traces. This can be done using continuation passing style (CPS) transformations, as in WebPPL and Church~\cite{mobus2018structure,goodman2012church}, or algebraic effects as in Pyro~\cite{bingham2019pyro}. In \pupil we model conditional distributions as monads~\cite{scibior2015practical}, and realise probabilistic programs as a GADT.

\subsection{Monads}
Monads are a design pattern commonly used in functional programming languages.

The key data structure I use to model probability distributions is a monad. A data type is a monad if it defines two operations, \texttt{return} and \texttt{bind}, and can be thought of as a type which `wrap' values. The return function takes a value and returns a monad wrapping that value. The bind function takes a monad and a function, and applies the function to the value wrapped inside the monad, and then re-wraps this value. The type must also satisfy a set of laws, which I omit here~\cite{wadler1990comprehending}. Monads can be used to structure programs in a general way, and allow side effects to be described in types.

\paragraph{Probability Monad} \label{sec:prep-monad}
It has been shown that probability distributions form a monad,~\cite{giry1982categorical, jones1989probabilistic}, and that they can be used to create distributions composed from other distributions~\cite{ramsey2002stochastic}. In this case, \texttt{return x} represents a distribution with only one value (x) - known as a Dirac distribution. So \texttt{bind d f} is the main operator for composing distributions. Binding distributions together represents taking the output of one distribution (d) and using it in the body of the function (f). This can be thought of as taking a sample from d. However, it is important to note that calling bind will not directly produce a sample, but expose that structure to an interpreter (the inference engine) which can then decide what to do at that point.

\paragraph{Custom let operators}
OCaml 4.08 allows me to define definitions for custom let operators. This is used to provide syntactic sugar for working with monads, and is similar to do-notation in Haskell. The reference documentation \footnote{\url{http://caml.inria.fr/pub/distrib/ocaml-4.08/ocaml-4.08-refman.html\#s\%3Abinding-operators}} specifies that a monad should provide a module which implements the (let*) and (and*) operators. The (let*) operator is the standard bind function - it takes the identifier bound to as the first argument to the function in bind. The (and*) operator is the product operation, it takes two monads and returns the monad product of the arguments - it has signature \texttt{'a m -> 'b m -> ('a * 'b) m}, where m is the monad type. An example, using the Option monad is given below to show the transformation that takes place. This feature allows the user to not have to use the bind (often aliased by >>=) or product functions explicitly, and offers a more intuitive syntax.

% TODO: add text within frame
\begin{figure}[!htb]
  \centering
  \begin{minipage}{0.45\textwidth}
    \centering
    \ocamlcode[label={New Syntax}]{code_snippets/old_monad.ml}
  \end{minipage}
  \begin{minipage}{0.45\textwidth}
    \centering
    \ocamlcode[label={Old Syntax}]{code_snippets/old_monad.ml}
  \end{minipage}
  \captionof{listing}{New let syntax which makes monadic binds easier to express}
\end{figure}

\subsection{Modules}
The module system is a key feature of the OCaml language. Every function in OCaml is in a module, by default the name of the file it resides in. Modules can also have signatures, which define what code is visible to a user, and constrain the module. Modules can hide types and implementations to provide a clean API, and are often used to wrap a particular type, for example a list or map. This means that to create or manipulate that type, the user must go through the module's API, ensuring only permitted operations are carried out. This is a feature I've used in designing distribution types. Modules can also be dynamically created from other modules, using functors, which are functions from modules to modules. This technique is used extensively in the Core library, and it allows modules to be customised and extended.

In OCaml, the module language (functors, modules, signatures, etc.) and the core language (functions, values, types, etc.) are considered separate, and values can't contain modules. First class modules provide a way around this constraint, and modules can be used in much the same way as ordinary values. This means a library can define functions to create modules which can then be used by other functions.

\subsection{Owl}

Owl is a scientific computing library written for OCaml \cite{owl}. It contains functions for working with a wide variety of probability distributions, e.g. normal, beta, binomial, etc. In particular, it is important to be able to find the probability density function (pdf) of distributions and to efficiently sample from distributions - these are the functions needed to perform inference. The distributions available in Owl form the primitive distributions I support, and are the building blocks of a probabilistic model.

Owl also provides many efficient helper functions, which can be used to calculate statistics over arrays of samples. Another important feature of Owl is the plotting API for which I wrote a wrapper to easily visualise output distributions from my PPL.

%% PREPARATION

\section{Probabilistic Programming}
Probabilistic programming is a programming paradigm where statistical models can be written as code and analysed. Models are a collection of random variables and the relationships between them.

Existing PPLs take two main forms - they can be standalone or embedded in another language. Standalone languages have their own syntax and compiler, so can be fine tuned to the task of inference, but often lack features since they have to be built from scratch. Embedded languages can utilise facilities in their host language, such as type checking, compilers or libraries, as well as allowing programs to be integrated into existing systems easily. However they need to work around the syntax and semantics of the host language.

The other main trade-off made in the design of PPLs is the range of models that can be expressed in the language against the efficiency of inference. Many languages restrict the set of allowed models in order to use more efficient inference algorithms which can take advantage of the restricted structure of models. Universal languages can represent any model, but suffer from less predictable inference procedures since many properties of the model (such as the number of random variables) are not available at compile-time. Overall, the more general models that need to be supported, the less efficient inference is.

There are two main approaches to building PPLs. One approach is graph-based, where a finite graph representing the variables and their relationships is generated from a program, over which efficient inference can take place. This approach is used in languages such as Infer.NET or JAGS, and has the benefit of being able to process high-dimensional data well, since efficient computation graph frameworks can be leveraged - another example is Edward \cite{edward}, which uses TensorFlow as a backend. This approach restricts the types of models to those that can be represented by the underlying graph.

Another approach, taken by the PPLs such as Anglican or WebPPL, is trace-based. This approach considers execution traces, with a `trace' being one run of a program, where the intermediate random variables take a particular value. Inference algorithms reason about these traces in order to produce a posterior distribution. A trace-based approach can lead to more models being able to be expressed, since we are not limited by the constraints of a graph. However, inference is often slower, since inference algorithms need to be more general purpose, and often converge slower. I have taken a trace-based approach in OwlPPL in order to allow my language to represent models which uses regular OCaml language constructs.

\subsection{Bayesian Inference}
Inference is the key motivating feature of probabilistic programming, and is a way to find a distribution over some input parameters based on the data we observe. The main feature of Bayesian inference is that we assign every model some prior belief. Often this prior is chosen based on our knowledge of the problem, but the prior can also be uninformative. The goal of Bayesian inference is to calculate the posterior distribution, which can be represented by Bayes' formula,
%
\[P(\theta\mid x)=\frac{P(x\mid\theta)P(\theta)}{P(x)}\propto{{P(x\mid\theta)P(\theta)}} \]
%
with $P(\theta)$ being the prior, and $P(x\mid \theta)$ being the likelihood model we define - the probability of observing the data given some parameters $\theta$. Both $x$ and $\theta$ are often vectors of variables, representing multiple parameters and observations respectively.

Unfortunately, exact Bayesian inference is usually computationally infeasible, especially when the number of random variables  we consider is large. The main issue is computing the normalising factor $P(x)$,
\[P(x)=\int_{\Theta}P(x,\theta)~d\theta\]
This represents marginalising $x$ out of the joint distribution by summing over all possible values of $\theta$. If the state space becomes very large (or infinite), or if $\theta$ is a very large vector, computing this exactly is intractable. For some distributions, this integral does not even have a analytic solution.

In the PPL setting, the prior is the generative model we define and conditioning statements define the likelihood model. Running the program forward without inference produces samples from the prior. Running inference on the program produces a new distribution, the posterior. Since the exact distribution usually can't be computed, inference algorithms I implement return distributions which can only be sampled from. Other statistics (e.g., mean, pdf, etc.) can then be estimated by taking a large number of samples.

\subsection{Inference Algorithms}
% https://ermongroup.github.io/cs228-notes/inference/sampling/
% https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/lectures/lecture17.pdf

% https://www.cs.ubc.ca/~fwood/teaching/OXWASP_CDT/probabilistic_programming.pdf
% http://www.robots.ox.ac.uk/~fwood/anglican/assets/pdf/Wood-AISTATS-2014.pdf

Inference algorithms are ways to systematically generate samples from posterior distributions given a likelihood function and a prior distribution. In trace-based PPLs, a model consists of latent (internal) variables and observed variables, and a single execution of a model (a program) can be thought of as an assignment to each of these variables, known as an \textit{execution trace}. This can be defined mathematically as below, by Bayes' rule:
%
\begin{equation} \label{eq:trace}
  p(x_{1:N}\mid y_{1:N})\propto \tilde{p}(y_{1:N},x_{1:N})
\end{equation}
%
Note that the trace may have a different number of variables each time a model is run, due to the fact that we allow general models which allow for unbounded recursion.

In \eqref{eq:trace}, $p$ is the posterior distribution of a particular trace $x$, given the observed variables $y$. This is proportional to the joint distribution of all the variables ($\tilde{p}$). The aim is then to find the posterior over the latent variables we are interested in (by marginalising out the other variables). We can specify which variables we care about within the program, either as part of the model, or outside it in a query to the model.
% TODO: put in equation of marginalissation, explain marginalisation more.

In general, there are two classes of inference algorithms - static and dynamic \cite{gordon2014probabilistic} which correspond roughly to graph-based and trace-based PPLs respectively. In static methods, the program is compiled to a static structure (e.g. a Bayesian network), which is analysed for inference to be performed. These methods generally constrain the models that can be represented (often to finite graphical models). Since my PPL aims to be universal, I focused mainly on dynamic methods, which use sampling to run programs and use conditioning statements that occur on these runs to perform inference.

\subsubsection{Exact Inference}

Exact Inference is the simplest method of calculating the posterior, but is usually computationally intractable. It involves calculating Bayes formula exactly, of which calculating the normalising constant is usually the problem. For discrete posterior distributions it can be thought of as calculating the probability of every possible value of the variable of interest. Since a random variable will be dependent on several others, this involves enumerating every possible combination of these variables and their outcomes.

\subsubsection{Rejection Sampling}

Since exact inference is too difficult in practice, we usually have to resort to \textit{Monte Carlo} \cite{monte-carlo} methods which rely on repeated sampling to infer properties of a distribution.

One such method, rejection sampling, is a very simple inference method which uses a `proposal' distribution which \textit{can} be sampled from. We take samples from the proposal distribution, and either accept or reject them. How likely we are to accept or reject a sample depends on the pdf of this proposal distribution. It can be shown that samples taken using this method converge to the required distribution \cite{flury1990acceptance}.

\subsubsection{Importance Sampling}

Importance sampling is another simple method improving on rejection sampling. It also uses a proposal distribution that can be sampled from. We calculate the ratio of the likelihoods between the two distributions to weight samples from the proposal. From doing this repeatedly with multiple samples from the proposal, we can build a posterior represented by a set of weighted samples.

\subsubsection{Monte Carlo Markov Chains (MCMC)}

MCMC methods involve constructing a Markov chain with a stationary distribution equal to the posterior distribution. A Markov chain is a statistical model consisting of a sequence of events, where the probability of any event depends only on the previous event. The stationary distribution is the distribution over successive states that the chain converges to (if it converges to one).

There exists several algorithms for finding this Markov chain, for example Metropolis-Hastings. Several MCMC algorithms require that we have a function, $f(x)$, which is proportional to the density of the distribution. The function is easy to compute for the posterior, since it is simply the prior multiplied by the posterior - the normalising constant can be ignored since we only need a proportional function.

MCMC algorithms have the same basic structure - to first `run' the chain for a burn-in period, taking samples and discarding them. Then, running the chain and collecting the states visited as samples. This set of samples is then a set of samples from the posterior, since the posterior should be equal to the stationary distribution. An important trade-off is made in the length of the burn-in period - too long and time is wasted discarding states, but too short and the chain will not converge to the correct distribution.

\subsubsection{Sequential Monte Carlo (SMC)}

SMC methods are algorithms which are based on using large numbers of weighted samples (`particles') to represent a posterior distribution. SMC methods are also known as particle filters. A particle is a value paired with an unnormalised weight which represents the likelihood of that value in the distribution. These particles are updated when data is observed and re-sampled from in order to converge the set of particles to the posterior.

For a set of weighted particles,
\[{\{(x^{[i]}, w^{[i]})\}}_{i=1..N}\]
%
the pdf of this distribution is given by
%
\[
  p(x) = \sum_{i=1}^{N}w^{[i]}\delta_{x^{[i]}}(x)
\]
where $\delta$ is the Dirac distribution.

The simplest SMC algorithms are particle filters \cite{particlefilter}, which simply resample particles on encountering new data, updating the weights of the particles based on how likely this data is deemed to be. However, many variations exist - the resampling method, updating the weights and the initialisation of particles can all be varied. The common feature of SMC algorithms is that they sequentially create sets of particles which converge to the desired distribution.

\subsubsection{Particle Monte Carlo Markov Chain (PMCMC)}
% TODO: pros/cons of all these?
SMC methods can also be combined with MCMC methods. These algorithms are known as particle Monte Carlo Markov chain (PMCMC) algorithms, and were first introduced for probabilistic programming in the Anglican language \cite{anglican-smc}. PMCMC methods are essentially MCMC algorithms which use an SMC algorithm as a proposal distribution.

\section{Professional Practice}

I adopted several best practices in order to ensure the project was successful. This includes performing regular testing, splitting code into separate modules designing signatures first, and ensuring my code follows a consistent style\footnote{\url{https://opensource.janestreet.com/standards/}}.

\subsection{Testing} \label{sec:prep-testing}
% google "unit testing probabilistic functions"
% google "unit test mcmc sampler"
% https://discourse.mc-stan.org/t/advice-for-testing-probabilistic-code/9451
The statistical nature of my library makes it difficult to write thorough unit tests for inference and sampling procedures. Ensuring posterior samplers are correct is a difficult problem due to inherent randomness, and the solutions to this I implemented are covered in section \ref{sec:impl-testing}.

Despite this, there is a suite of unit tests for individual deterministic functions. This is especially important for deterministic helper functions which should always work the same way, and unit tests allow regressions to be caught. I also used the \texttt{Quickcheck} library to perform some unit tests, which allows me to ensure certain invariants are preserved by automatically testing on many randomly generated inputs. I use the \texttt{bisect\_ppx} library to produce code coverage reports to ensure I am thoroughly testing code.

%% IMPLEMENTATION

\section{Language Design}
% specify DSL here
I chose to implement my language as a domain specific language (DSL), shallowly embedded into the main OCaml language. Using a shallow embedding means we can use all of the features of OCaml as normal, including branching (if/then/else), loops, references, let bindings, (higher-order) functions, and recursion. This has the benefit of leveraging OCaml features such as type checking, as well as permitting library code to be included directly within models.

Using a shallow embedding allows for recursively defined models. This can allow non-terminating (and therefore invalid) models to be defined. However, we can write functions which are \textit{stochastic recursive} \cite{siegmund}, that is, functions which have a probability of termination that tends to 1 as the number of successive calls tends to infinity. This leads to functions which terminate their recursion non-deterministically. Any model which does not satisfy this will be considered an invalid model - unfortunately as it is not possible to determine whether or not a program will halt, this property cannot be enforced.

An embedded PPL can be thought of as being the same as the host language, except for two extra operators:
\begin{itemize}
\item sample - for taking a sample from a distribution, either a primitive distribution or another (sub-)model.
\item condition - for conditioning on observations, defines how likely data observed is (also called observe or score in other PPLs).
\end{itemize}
The problem of designing a PPL is then finding a way to model the nondeterminism in the sample operator and integrate the information from the condition operator to guide inference and the execution traces explored. Most universal PPLs use a feature that enables exploring subcomputations - the different execution traces. This can be done using continuation passing style (CPS) transformations, as in WebPPL and Church \cite{mobus2018structure,goodman2012church}, or algebraic effects as in Pyro \cite{bingham2019pyro}. In order to achieve a similar effect, I model conditional distributions as monads in OwlPPL, as in \cite{scibior2015practical}, and realise probabilistic programs as a GADT.

\paragraph{Log Probabilities}
Calculating probabilities can often lead to underflow, since it is common to multiply many small probabilities together. To avoid this, I use logs of probabilities internally and add logs where I would multiply the original probabilities. This behaviour can be changed by changing the \texttt{Prob} module used by the \texttt{Dist} module - the documentation for \texttt{Prob} is in appendix \ref{app:docs}.

\section{Representing Distributions}
In order to define my DSL, I use 3 different data structures to represent the different types of distribution I use:
\begin{itemize}
\item Input distributions - primitive distributions that are used to build models.
\item General probabilistic models - composed primitives conditioned on data.
\item Output distributions - empirical distributions built from a set of samples from a posterior.
\end{itemize}
\vspace{2mm}
\subsection{Primitive Distributions}
In PPLs, users build complex models by composing more simple elementary primitive distributions for which we have extra information such as exact equations and the ability to sample directly. These primitive distributions need to have a few operations defined on them, namely \texttt{sample, pdf, cdf, ppf} (inverse of cdf) and \texttt{support} (the set of values that a distribution can take). These are all standard properties of distributions, and are used to perform inference.

An extension goal achieved here is to allow users to define their own primitive distributions if they have not already been defined in the library. For example, I have not implemented the Poisson distribution as a primitive distribution, but you can imagine models which need to use the Poisson as a building block. To achieve this, the user simply has to write a function which takes the parameters of the distribution as arguments and return a first class module matching the primitive distribution signature. This technique also allows users to use modules that they may have already defined, and constrain them to the required signature for use in the PPL.

The type of a primitive distribution is
\begin{center}
  \mintinline{ocaml}| type 'a prim_dist = (module PRIM_DIST with type t='a)|
\end{center}
with the \texttt{PRIM\_DIST} signature defined as in Listing \ref{lst:prim-sig}.

% TODO: put these side by side instead
\begin{figure}[!htb]
  \begin{minipage}{0.5\textwidth}
    \ocamlcode{code_snippets/prim_sig.ml}
    \captionof{listing}{Signature of the module that primitive distributions must implement}
    \label{lst:prim-sig}
  \end{minipage}
  \begin{minipage}{0.5\textwidth}
    \ocamlcode{code_snippets/new_dist.ml}
    \captionof{listing}{Adding a new distribution as a primitive}
    \label{lst:new-dist}
  \end{minipage}
\end{figure}

% \begin{listing}[!ht]
%   \ocamlcode{code_snippets/prim_sig.ml}
%   \caption{Signature of the module that primitive distributions must implement}
%   \label{lst:prim-sig}
% \end{listing}

An example of this being used to add a new primitive distribution is given in Listing \ref{lst:new-dist}, for the specific case of the Poisson distribution. The \texttt{Poisson} distribution can now be used as other primitives are, e.g. in \texttt{observe} statements.

% \begin{listing}[!ht]
%   \ocamlcode{code_snippets/new_dist.ml}
%   \caption{Adding a new distribution as a primitive}
%   \label{lst:new-dist}
% \end{listing}

\subsection{General Probabilistic Models}
Statistical models are designed by the user to model a process they are interested in and are given as the input to inference procedures. They are built up from primitive distributions, and should be both composable (in order to build bigger models) and amenable to inference procedures.

\subsubsection{Probability Monad}

As mentioned in section \ref{sec:prep-monad}, monads are a natural way to represent composable probability distributions. They allow the output from one distribution (essentially a sample), to be used as if it was of the type that the distribution is defined over. Essentially, the \texttt{bind} operation allows us to 'unwrap' the 'a dist type to allow us to manipulate a value of type 'a. We must then use \texttt{return} to `wrap' the value back into a value of type 'a dist. The type signatures of these functions are below, with \texttt{m} being the monad type.
% \begin{noindent}
\begin{figure}[!htb]
  \centering
  \begin{cminted}{ocaml}
    val bind: 'a m -> ('a -> 'b m) -> 'b m
    val return: 'a -> 'a m
  \end{cminted}
\end{figure}
% \end{noindent}
Using monads also allows us to define several helper functions which can be used when working with distributions. For example, we can `lift' operators to the \texttt{dist} type, for example allowing us to define adding two distributions over integers or floats using liftM or liftM2. We can also fold lists of distributions using a similar technique.

Using monads also allows the use of the extended let operators introduced in OCaml 4.08. These allow the definition of custom let operators, which mimic do-notation in Haskell. This means that sampling from a distribution (within a model) can be done using the \texttt{let*} operator, and the variable that is bound to can be used as if it were a normal value. The one caveat is that the user must remember to \texttt{return} at the end of the model with whatever variable(s) they want to find the posterior over. The \texttt{and*} operator can also be used when we use several independent distributions in a row. This can make for more efficient sampling (and inference) since more structure is encoded. It is also a common pattern to set up a model by first independently drawing from several distributions, as below.

% \begin{noindent}
\begin{listing}
  \begin{ocamlcode-in}
    (* two independent draws from standard normals *)
    let* x = normal 0. 1.
    and* y = normal 0. 1. in
    (* ...rest of model  *)
    return (x + y)
  \end{ocamlcode-in}
  \caption{Use of \texttt{and*} for independent draws}
\end{listing}
% \end{noindent}

I define my own functor for monads in order to automatically generate several helper functions. This takes a module with the basic monad functions and extends it with helper functions defined in terms of return and bind. The full module documentation for this can be found in appendix \ref{app:docs}. An example is the liftM2 function, which allows normal operations to be lifted to distributions, e.g. an addition operator for the output for two distributions can be simply created by lifting the normal addition operator, allowing distributions to be naturally `added'.

% \begin{noindent}
\begin{listing}
  \begin{ocamlcode-in}
    let ( +~ ) = liftM2 ( +. )
    (* the distribution of the sum of 2 independent draws from standard normals *)
    let d = (normal 0. 1.) +~ (normal 0. 1.)
  \end{ocamlcode-in}
  \caption{Lifting addition to distributions}
\end{listing}
% \end{noindent}

However, there are many different underlying data structures which can be used to represent distributions which conform to the definition of a monad. The simplest is a list of pairs representing a set of values and corresponding probabilities, \texttt{('a * float) list}. This is a natural way to represent discrete distributions, with return and bind defined as in Listing \ref{lst:monad_plist}. Here, \texttt{return} gives us the distribution with just one value, and bind combines a distribution with a function that takes every element from the initial distribution and applies a function that creates a set of new distributions. The new distributions are then flattened into a single list and normalised. This approach has been used to create functional probabilistic languages \cite{erwig}, but has several drawbacks, primarily the fact that it cannot be used to represent continuous distributions, and that inference is not efficient - there is no information from the model encoded in this representation, such as how random variables are combined or from what distributions they came from.

\begin{listing}[!ht]
  \ocamlcode{code_snippets/probmonad_list.ml}
  \caption{Probability monad as a List}
  \label{lst:monad_plist}
\end{listing}

Another issue is that flattening distributions is inefficient since duplicate values must be combined, and this approach is $O(n^2)$ when using a list since we scan up to the length of the entire list for every element. A better option is to use a map, which is provided in Core, and implemented as a balanced tree, significantly improving the time complexity of combining distributions.

\begin{listing}[!ht]
  \ocamlcode{code_snippets/probmonad_map.ml}
  \caption{Probability monad as a map}
  \label{lst:monad_pmap}
\end{listing}

Although this is not the final data structure I chose for general probabilistic models, it is the one I used for discrete empirical distributions.

\subsubsection{GADT} \label{sec:gadt}

The structure that I selected to represent general models is a generalised algebraic data type. GADTs are often used to implement interpreters in functional languages, and have been used to represent probabilistic models. The GADT I implement here (and some inference algorithms) is based on (Scibior et al. 2015) \cite{scibior2015practical}. This represents a model in a very general way, and can then be `interpreted' by a sampler or an inference algorithm. For sampling, I traverse the model, ignoring conditionals to enable forward sampling from the prior.

For inference, I provide some inference functions as transforming conditional distributions to distributions without any conditional statements, allowing sampling to be performed as normal. Some inference functions are also implemented by generating an empirical distribution that can be sampled from similarly.

Listing \ref{lst:gadt1} shows each of the variants. The monad functions are also provided, which construct the corresponding variants in the GADT - \texttt{Return} represents a distribution with only one value, and \texttt{Bind} contains a distribution and a function, which represents that function being applied to the output from that distribution, and is also bound to \texttt{(let*)}. The product function is used for models with independent sub-parts, such as drawing samples from many independently distributed variables, and could be used to parallelise models. The \texttt{Independent} variant is also bound to \texttt{(and*)}.

Primitive distributions have a variant which takes the primitive distribution type. We can find the exact pdf/cdf of these distributions, unlike the more general \texttt{dist} type, which can only be sampled from.

The \texttt{Conditional} variant is used to assign scores (likelihoods) to execution traces, and contains a function which takes an element produced by a model and returns a score for the corresponding trace. I define several wrappers over this variant to represent different types of conditioning, outlines in section \ref{sec:condition}.

\begin{listing}[!ht]
  \ocamlcode{code_snippets/gadt.ml}
  \caption{Representing a probabilistic model using a GADT}
  \label{lst:gadt1}
\end{listing}

An important feature of this type is that it is polymorphic - this allows distributions to be defined over any type, including arbitary ADTs or even distributions themselves.

\subsection{Empirical Distributions}

The output of Bayesian inference is a probability distribution over the variables we are interested in. Ideally, we would be able to produce an exact posterior distribution, and be able to extract exact relevant statistics. However, approximate inference only allows us to create functions to sample from this posterior. We can define a signature for a type of an empirical distribution that is created from posterior distributions by taking many samples. This can then be used to calculate useful statistics - e.g. mean, variance, pdf, cdf, etc.. The type is abstract to allow different implementations for discrete and continuous distributions.

For discrete distributions, I use a \texttt{Core.Map}\footnote{\url{https://ocaml.janestreet.com/ocaml-core/latest/doc/base/Base/Map/index.html}}, with the keys being the values that the distribution can take and the values the number of samples with that value. Continuous distributions use a dynamically resizing array - adding each sample is then $O(1)$ amortized, and statistics can be calculated using Owl's functions that operate on arrays. A constraint on continuous distributions of this type is that they are defined over floats, and only represent one dimension.
% Creating values with these types required passing a first class module representing the type of the keys - this is so that an appropriate compare function can be used in the internal tree data structure.

% I also provide modules which are backed by the polymorphic versions of these data structures (\texttt{Core.Map.Poly}). These types don't require the use of first class modules to create objects, since the keys are compared using the polymorphic compare function. While this makes using the module simpler to use (no need to pass the first class module), it also makes them more inefficient due to the use of polymorphic comparison.

\begin{listing}[ht]
  \ocamlcode{code_snippets/empirical_sig.ml}
  \caption{Signature for empirical distributions}
  \label{lst:empirical}
\end{listing}

The signature in Listing \ref{lst:empirical} is implemented for both continuous and discrete distributions. For the continuous case, I perform binning to approximate the continuous distribution by a discrete one in order to approximate the pdf. The number of bins used is calculated automatically from the number of samples taken.

\section{Conditioning} \label{sec:condition}

The GADT described in section \ref{sec:gadt} can be used to describe general models, in particular conditional distributions, thanks to the \texttt{Conditional} variant. Without this variant, we can only define prior distributions, but including it means we can incorporate observed data into our models and perform inference.

% https://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2017thesis.pdf - section on conditioning, pg.42
The condition variant in my GADT is used to assign scores to traces, and takes a function which takes an element and returns a float, a `score'. This score represents how likely the current trace is, given the value passed to the function. In this way, we can represent observations.

I have also implemented a few helpers to make it easier to condition models. The three main helpers are \texttt{condition}, \texttt{score} and \texttt{observe}, which are all specific cases of the general \texttt{Condition} variant.

The \texttt{condition} operator is used for hard conditioning, which conditions the model on an observation being true. If true is passed in, then the score assigned is 1, and if false, the score assigned is 0. This score represents how likely it is for the current trace to occur, and different inference algorithms will use this information to produce a distribution over all possible traces. We can use this operator to constrain certain variables or outcomes in a model. For example in Listing \ref{lst:dice}, we roll two dice and observe that the sum is 4 - we can then find the distribution over the first die (which won't include 4,5 or 6 since they are >=4).

This function is mostly useful for discrete models when using equality in this manner, since the probability of observing any given value in a continuous distribution is zero. However, if we are dealing with ranges, then we can use hard conditioning as in Listing \ref{lst:half_normal}, which constrains the standard normal distribution to be positive.

\begin{figure*}[!htb]
  \begin{minipage}{0.5\textwidth}
    \ocamlcode{code_snippets/dice_conditioning.ml}
    \captionof{listing}{Hard conditioning for discrete model}
    \label{lst:dice}
  \end{minipage}
  \begin{minipage}{0.5\textwidth}
    \ocamlcode{code_snippets/half_normal.ml}
    \captionof{listing}{Hard conditioning for continuous model}
    \label{lst:half_normal}
  \end{minipage}
\end{figure*}

For soft conditioning, for example an observation that we know comes from a certain distribution, there is an \texttt{observe} function. This function is essential for continuous distributions, since the probability of observing any one value is 0, making hard conditioning redundant since it will just assign a score of zero to every trace. Instead, we can use the pdf of the distribution to determine how likely that observation is in the model.

The \texttt{score} function is similar to the condition operator, except instead of 0, it assigns a particular constant score to the trace. This is generally used in a branching statement, where a constant score will be assigned depending on some (deterministic) condition.

% \begin{noindent}
\begin{listing}[!htb]
  \centering
  \begin{ocamlcode-in}
    let condition b d = Conditional((fun _ -> if b then 1. else 0.), d)
    let score s d = Conditional((fun _ -> s),d)
    let observe x dst d = Conditional((fun _ -> Primitive.pdf dst x),d)
  \end{ocamlcode-in}
  \caption{The definitions of the different conditioning operators}
  \label{lst:cond}
\end{listing}
% \end{noindent}

\section{Forward Sampling}
% https://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2017thesis.pdf - sec 7.1, pg 135
The simplest operation to define on models is to sample from them. Sampling from conditional distributions requires inference, and is discussed in section \ref{sec:inference}. Here, we run a probabilistic program 'forwards', that is, running a generative model and seeing the outputs without conditioning on observed data.

In PPLs, a complete program is a posterior distribution of a parameter given some observed data, $P(\theta\mid x)$. The generative model, i.e. the program without condition statements, is the prior distribution, $P(\theta)$. The condition statements then define the likelihood model, $P(x\mid \theta)$, the probability of the observations in the current model. So sampling from the prior is the same as sampling normally, but ignoring the conditionals (essentially ignoring the data).

We can also take into account the conditionals, and produce weighted samples, with the weight being the score assigned by each conditional branch, accumulated by multiplying all the scores. This gives us a set of values with corresponding weights which represent how likely those values are. An important property of these weights is that they are not normalised, so we cannot use them to find the posterior directly. I have implemented several variants of functions for finding the prior and sampling, all with the same concept as Listing ref{lst:sampling}.

\begin{listing}[!htb]
  \centering
  \ocamlcode{code_snippets/prior_sample.ml}
  \caption{Sampling functions}
  \label{lst:sampling}
\end{listing}

The function for generating a prior does not directly take samples, but manipulates the structure of the dist GADT. For example, in the \texttt{Bind} branch, it actually introduces 2 new bind variants (via \texttt{let*}) which produces a new distribution lazily. This makes it easier to use the prior within inference algorithms, and allows it to be composed with other distribution modifying functions.

\section{Implementing Inference} \label{sec:inference}

Inference is the key motivation behind probabilistic programming. Up to this section, I have discussed how to represent models but not do anything with them that couldn't be done in a standard language. With inference, we can produce a sampler which will accurately reflect a posterior distribution.

Inference can be thought of as a program transformation \cite{scibior2015practical, Zinkov2016ComposingIA}. In my ppl, this corresponds to a function of type \texttt{'a dist -> 'a dist}. This method allows for the composition of inference algorithms, exemplified in section \ref{sec:pimh}.

% use equations from here: https://arxiv.org/pdf/1507.00996.pdf

% Since I have used a trace-based approach, we can characterise the posterior probability of a trace as (from the previous chapter):
% % https://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2017thesis.pdf - pg.52
% $$p(x_{1:N}|y_{1:N})\propto\tilde{p}(y_{1:N},x_{1:N})$$

% We can now see how this formula corresponds to a program in my ppl. The example below is a very simple model, which adds two numbers drawn from discrete distributions, and observes a value.

% TODO: write example program, and relate to terms in formula

\subsection{Enumeration (Exact Inference)} \label{sec:enum}
Enumeration is the simplest way to perform exact inference on probabilistic programs, and essentially consists of computing the joint distribution over all the random variables in the model. This involves enumerating every execution path in the model, in this case performing a depth first search over the \texttt{dist} data structure. For every \texttt{bind} (i.e. every \texttt{let*}), there is a distribution ($d$) and a function from samples to new distributions ($f$). I call this function on every value in the support of the distribution $d$, and then enumerate all the possibilities. The final output is a \texttt{('a * float) list}, from which duplicates are removed and is then normalised, so that the probabilities sum to one.

\begin{listing}[ht]
  \ocamlcode{code_snippets/enumerate.ml}
  \caption{Enumerating all paths through a model}
  \label{lst:enum}
\end{listing}

This method is very naive, and therefore inefficient. Since we essentially take every possible execution trace, we do not exploit structure such as overlapping traces. This can be made slightly more efficient by using algorithms such as belief propagation \cite{belief-prop}, but they still only work on models made up from discrete distributions (and are not compatible with the way I represent models). Exact inference of this kind only works on models that can be represented as finite networks, and for Bayesian networks is in fact NP-hard \cite{cooper1990computational}. So instead, most of my project focuses on approximate inference.

\subsection{Rejection Sampling} \label{sec:rej}
% https://www.cs.ubc.ca/~schmidtm/Courses/540-W18/wood.pdf pg30
% Ancestral sampling, very good explanation of rejection
% Why rejection doesn't work for continuous, so must use importance instead -->
% http://www.cs.tut.fi/~elomaa/teach/AI-2013-9.pdf
% Hard rejection
In my implementation of rejection sampling, I take samples from the prior, with accumulated scores. If the score is above some constant threshold, then the sample is accepted, and rejected otherwise. The specific case of the general rejection sampling algorithm used here sets the proposal distribution as the prior, and we use the scores to approximate the density function of the posterior (Listing \ref{lst:rej}).
% todo: code of rejection sampling

\begin{listing}[!htb]
  \centering
  \ocamlcode{code_snippets/rej.ml}
  \caption{Simplest rejection sampling method}
  \label{lst:rej}
\end{listing}

This method is naive, since it runs an entire trace even if the first condition dropped the score below the threshold. An optimisation I implemented is to short-circuit this, and reject as soon as the trace goes below the threshold. It is also implemented as a dist transformation, so can again be used with the same sample methods.

This particular function is hard rejection, since samples with a lower score are always rejected. I have also implemented functionality to perform `soft' rejection. This method instead sets the probability of acceptance being the score attached to the sample.

A problem with rejection sampling is if conditions make most execution traces very unlikely, it will take a very large number of samples to have enough (or any) accepted samples. An example is given in Listing \ref{lst:bad-reject}, where the condition only has a 1\% chance of being true. This means that, on average, for every 1000 samples, we will only accept one.

% \begin{noindent}
\begin{listing}[!htb]
  \centering
  \begin{ocamlcode-in}
    let* x = bernoulli 0.001 in
    condition (x=0)
    (return x)
  \end{ocamlcode-in}

  \caption{An example of a model that is very inefficient under rejection sampling}
  \label{lst:bad-reject}
\end{listing}
% \end{noindent}
%
\subsection{Likelihood Weighting (Importance Sampling)} \label{sec:likelihood-wighting}
% http://www.cs.tut.fi/~elomaa/teach/AI-2013-9.pdf

Likelihood weighting is an importance sampling method, when the proposal distribution we use is the prior. We want any algorithm we use to be as general as possible, and not need to be tuned using auxiliary distributions chosen by hand. Since for any model we can find the prior distribution easily, it is natural to use this as a proposal distribution here - this can be seen in several of the implementations of inference.

The implementation of likelihood weighting is simple - we simply take a set of samples (with weights) from the prior, remove duplicates and normalise, and use this set of particles as a the categorical distribution representing the posterior.
% \begin{noindent}
\begin{listing}[!htb]
  \centering
  \begin{ocamlcode-in}
    let importance n d =
    let particles_dist = sequence @@ List.init n ~f:(fun _ -> prior d) in
    let* particles = particles_dist in
    categorical particles
  \end{ocamlcode-in}
  \caption{Likelihood weighting}
  \label{lst:imp}
\end{listing}
% \end{noindent}

The sequence function is a monad function that takes a list of distributions and fold them together so that they act as a single distribution returning entire lists. This allows the use of \texttt{(let*)} to sample a set of particles at once, and use them directly as the distribution.
% code of importance sampling.

\subsection{Metropolis Hastings (MCMC)} \label{sec:mh}
Metropolis Hastings is an MCMC algorithm, and so is used to find a Markov chain with the stationary distribution equal to the target distribution, here the posterior. There are many variants of this algorithm, and the one I implemented is the independent metropolis hastings (IMH) algorithm. I use the prior as a proposal distribution, using scores as an approximation to a density function. The algorithm is outlined below.

\begin{itemize}
\item Let $\pi$ be the target distribution that we want to sample from.
\item Let $q$ be the density function of the prior, approximated by the scores.
\item Initialise by taking a sample from the prior as the first state in the chain.
\item Let x be a sample from the prior.
\item Let y be the last state in the chain.
\item Calculate the acceptance probability, $\alpha(x,y)$ by \eqref{eq:accept}
  \begin{equation}
    \label{eq:accept}
    \alpha(x,y) =
    \begin{cases}
      \min{\left( \frac{\pi(y)q(x)}{\pi{x}q(y)},1 \right) } & \pi(x)q(x) > 0 \\
      1                                                     & \pi(x)q(x) = 0 \\
    \end{cases}
  \end{equation}
\item The state x is then accepted with probability $\alpha(x,y)$. If accepted, we use x as the next state, or if rejected, we re-use y as the next state.
\end{itemize}

This produces a Markov chain with transition probability: \[p(x, y) = q(y)\alpha(x, y) \quad\quad y\neq x\]
It is known as `independent' metropolis hastings (IMH) since subsequent candidate states ($x$) are independent of previous values of states.

% https://probmods.org/chapters/inference-algorithms.html
% MCMC section
I have implemented IMH as a function transforming distributions (\texttt{'a dist -> 'a dist}). This allows it to be composed with other inference algorithms, as well as allowing the standard sample function to be used on the output. To model a Markov chain, I use a \texttt{Core.Sequence.t} - which is a data structure for a lazy list. The constructor takes a function that takes a previous state to produce a new state and output a value - analogous to the transition function. In this case, the output is the same as the state.

\begin{listing}[H]
  \centering
  \ocamlcode{code_snippets/mh.ml}
  \caption{Metropolis hastings}
  \label{lst:mh}
\end{listing}

One important property of the return distribution is that consecutive sample statements will need to return different values (to simulate running the chain). In order to achieve this, I create some mutable state - the sequence, which will take a step every time sample is called on the output distribution. In order to make sure this sequence is persistent, I use a reference and put it after a bind (let*) statement, incrementing the chain every time the function is called (which is only on sampling). Since the bind statement contains a function, the reference is closed over and is persistent to the output distribution.


\subsection{Bootstrap Particle Filter (SMC)} \label{sec:pf}
% https://probmods.org/chapters/inference-algorithms.html
% particle filter section
Particle Filters are a class of algorithms which use particles to approximate a posterior. This is similar to the technique I used in importance sampling (\ref{sec:likelihood-wighting}), but the difference here is that the particles are sequentially updated as we observe condition statements (i.e. as we observe data). In fact, an example of an smc algorithm is sequential importance sampling, but here I use an algorithm called the bootstrap filter \cite{particlefilter}.

The code given in Listing \ref{lst:smc} transforms a conditional distribution to a new conditional distribution. In order to find the posterior, we simply ignore the conditional by finding the prior after using the smc method.

\begin{listing}[!htb]
  \centering
  \ocamlcode{code_snippets/smc.ml}
  \caption{Particle Filter}
  \label{lst:smc}
\end{listing}

The GADT is traversed top down, with particles being initialised at a `leaf' - primitives or returns. From this root, bind functions apply functions to the particles, and conditional statements updates the weights and resamples. The \texttt{resample} function takes a set of particles and takes samples from this set with replacement - this is the `bootstrap' resampling method. The output distribution is conditioned by the total weight of all particles.

Increasing the number of particles finds a more accurate distribution with a finer resolution, but also increases the amount of time and memory required.

\subsection{Particle Cascade (SMC)} \label{sec:pc}
The particle cascade algorithm (also asynchronous sequential Monte-Carlo) is an algorithm introduced in (Paige et al. 2014) \cite{paige2014asynchronous}, that extends the particle filter. It uses a lazily generated infinite set of particles, which allows it to be `anytime', that is, it can generate more particles without having to start regenerate a large particle set from scratch. It also features a parallelisable re-sample step, although I will not make use of this feature, since I am not using multi-core OCaml.

The main implementation difference is that instead of resampling, a particle `branching' operation is used, which produces a lazily generated set of particles at each resample step. Each particle produces 0 or more children to be used in the next iteration.

\subsection{Particle-Independent Metropolis-Hastings (PMCMC)} \label{sec:pimh}

SMC and MCMC algorithms are two distinct classes of algorithms, but can be combined to produce more efficient inference procedures. A simple example of these algorithms is the particle-independent metropolis-hastings algorithm \cite{pmcmc}. This algorithm first uses a particle filter to find an approximation of the posterior, then uses this approximation as a proposal distribution for Metropolis-Hastings.

Due to the fact that my PPL allows composition of inference algorithms, a basic implementation is very simple. However, this composition is only possible since the \texttt{smc} function produces a dist with conditionals, which no other inference method does.

% \begin{noindent}
\begin{listing}
\begin{ocamlcode-in}
    let pimh k n d = mh k (Smc.smc n d)
\end{ocamlcode-in}
  \caption{Particle-Independent Metropolis-Hastings}
\end{listing}
% \end{noindent}

\section{Evaluation}
\label{s:evaluation}

Testing inherently statistical code is more complex than deterministic code. One could fix a random seed, ensuring the same sequence of results are produced but this is overly strict: we desire only that samples fit a distribution not that the same sequence is produced. A better approach is to perform hypothesis testing using, e.g.,~Kolmogorov-Smirnov~\cite{massey1951kolmogorov}, to ensure the correct distributions are produced but such tests are correctly expected to fail with a given rate making them unsuitable for unit testing. To evaluate the correctness of \pupil we use the $\chi^2$ and Kolmogorov-Smirnov (K-S) statistical tests that measure how similar two distributions are to each other (goodness-of-fit) by comparing the empirical distribution of 10,000 samples from an approximation to an exact distribution. All tests used a significance level $\alpha = 0.05$ with null/alternative hypotheses that the sample data follow/do not follow the desired distribution. All test statistics exceed 0.05, so we do not reject the null hypothesis in any case, indicating that the distributions are not significantly different at the 5\% significance level.

We use four example problems in our evaluation.

% \begin{figure}
%   \centering
%   \includegraphics[height=1.5in]{figs/sprinkler-network.png}
%   \caption{\label{fig:sprinkler-network}Sprinkler model as a network.}
% \end{figure}
\paragraph{Sprinkler}
The sprinkler model is an example of exact inference on a discrete model represented by a Bayesian network, % (Figure~\ref{fig:sprinkler-network})
a commonly used simple example in Bayesian inference. We model the probability of rain given that the grass is wet, itself dependent on whether or not it is raining or the sprinkler is on, and the probability of rain and the sprinkler being on are dependent on whether or not it is cloudy.

\paragraph{Biased Coin}
An example of exact inference on a continuous model involves a coin being flipped $n$ times that lands on heads $x$ times, where we seek the distribution over the weight of the coin (i.e., how likely it is to land on heads again). The likelihood model is a binomial, $X \sim \text{Binom}(n,\theta)$, and the prior is uninformative, $\Theta \sim \text{Uniform}(0,1)$.

\paragraph{Hidden Markov Models}
Hidden Markov Models (HMMs) are more complex, having a sequence of hidden states that emit observed states. There are two distributions involved, whether discrete or continuous: \one~the \emph{transition distribution} defining how likely the next state is given the current state, and \two~the \emph{emission distribution} over the observed states given the hidden state. Our model uses discrete distributions, with hidden and observed states \emph{True} and \emph{False}, starting state \emph{True}, and transition matrix
$T = \big(\begin{smallmatrix}
  0.7 & 0.3 \\
  0.3 & 0.7
\end{smallmatrix}\big)$
and emission matrix,
$O = \big(\begin{smallmatrix}
  0.9 & 0.1 \\
  0.1 & 0.9
\end{smallmatrix}\big)$.

\paragraph{Linear Regression}
Finally, this example uses multiple 2-D data points to infer a continuous (straight line) distribution$ y=\beta_1 x_1 + \beta_0 + \epsilon$ where  $\beta_i$ are the terms to be determined, and $\epsilon$ represents random error. A frequentist approach minimises the sum of least squares between the known values and the predicted outputs to find a single best set of values for the parameters. In Bayesian linear regression, we also use prior distributions to augment the data:   $y \sim N(\beta_0 + \beta_1 x_1 + \epsilon, 1.)$ as the likelihood model and $\beta_0 \sim N(0,1)$ and $\beta_1 \sim N(0,1)$ the priors over the slope and $y$-intercept.

\begin{figure*}
  \centering
  \begin{subfigure}[t]{\textwidth}
    \centering
    \input{tikz/times_plot.tex}
    \caption{\label{fig:time-perf}
      Inference time for different models and inference algorithms.}
  \end{subfigure}
  \begin{subfigure}[t]{\textwidth}
    \centering
    \input{tikz/mems_plot.tex}
    \caption{\label{fig:mem-perf}
      Memory usage for different models, all using an MCMC algorithm.}
  \end{subfigure}
  \caption{\pupil performance, taking 10,000 samples from the posterior, averaged over 20 runs. Results shown for Metropolis-Hastings (\emph{mh}), Bootstrap Particle Filter (\emph{smc}), and Rejection Sampling (\emph{rej}). Error bars show the 95\% confidence interval. }
\end{figure*}

All tests are carried out on a single core of an Intel\textsuperscript{(R)} Core\textsuperscript{(TM)} i5-7200U CPU @ 2.50GHz. We compare the performance of OwlPPL against Anglican and WebPPL, well-known universal PPLs embedded in different host languages, for those inference algorithms for which there are comparable implementations. Figures~\ref{fig:time-perf} and~\ref{fig:mem-perf} compares \pupil against these languages for a range of models and inference procedures. All the models have been tested to produce correct results when using the given inference procedures. We consider both running time and peak memory usage. We see that \pupil performs consistently better that WebPPL in both memory and time, perhaps because it uses NodeJS incurring interpretation overheads. It also exhibits less variance, except when using rejection sampling for the Coin model. \pupil slightly outperforms Anglican on the two continuous models except when using rejection sampling (the current implementation is quite naive) but is generally slower than Anglican for the discrete models. However, \pupil outperforms both Anglican and WebPPL in terms of peak memory usage. Although all three languages are garbage collected, OCaml generates native binaries rather than relying on a virtual machine, and so does not incur the overheads introduced by the JVM (used by Clojure, Anglican's implementation language) and the NodeJS runtimes.

\begin{figure}
  \centering
  \input{tikz/linreg_by_datasize.tex}
  \caption{\label{fig:time-datasize}
    Time taken for inference as a function of input data length as the mean of 10 runs each taking 1,000 samples from the posterior, shaded areas are the 95\% confidence interval ($\pm 2\sigma$)}
\end{figure}

It is also important to consider running time of inference as more data is used, as  models conditioned on more data should  give more accurate results. We evaluated  the linear regression model, increasing the length of the array used as input, and see that running time increases linearly with the size of data. Figure~\ref{fig:time-datasize} shows all inference functions running in time linear to the size of the input, albeit with substantial variation in constant factors, e.g.,~Sequential Monte Carlo has a much steeper gradient than Metropolis-Hastings.

\begin{figure*}
  \centering
  \input{tikz/kl_plot.tex}
  \caption{\label{fig:kl}
    Plot of KL-divergence with increasing number of samples for different models and inference procedures - average over 20 runs. I use a log y-axis here due to the wildly varying gradients of the functions - the curves shown map to lines on a linear axis.}
\end{figure*}

Figure~\ref{fig:kl} shows the trade-off between speed and accuracy: the particle filter is slower than rejection sampling here but produces more accurate posterior distributions. For each inference procedure, we can see that the KL-divergence for each model generally decreases as we take more samples. Rejection sampling is consistently the worst performing inference procedure, with particle based methods such as the particle filter or importance sampling generating more accurate distributions. These plots have all been smoothed by taking a moving average in order to reduce the impact of noise.

\section{Conclusion}
\label{s:conclusion}

We have presented the design and evaluation of \pupil, a universal probabilistic programming language shallowly embedded in OCaml. It can represent a wide variety of models, including infinite models with unbounded recursion, while supporting all the standard OCaml language features such as pattern matching or higher order functions. It allows models to be combined in complex ways, and existing OCaml libraries can be used within those models. Its performance is competitive with other universal PPLs, particularly the memory usage which is significantly lower than WebPPL and Anglican -- making it potentially appropriate for edge computing. \pupil is publicly available\footnote{\url{http://github.com/anik545/OwlPPL.git}}, and we welcome improvements.

% \begin{acks}
% \end{acks}

{
  \clearpage
  \bibliographystyle{ACM-Reference-Format}
  \bibliography{owl-ppl.bib}
}

\appendix
\end{document}
